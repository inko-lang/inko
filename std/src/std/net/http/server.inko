# HTTP 1.1 server support.
#
# This module provides types for implementing custom HTTP 1.1 servers.
#
# A server consists of at least two components:
#
# - An instance of `std.net.http.server.Server` that listens for incoming
#   requests
# - A type that implements `std.net.http.server.Handle` and handles the
#   incoming request and produces a response
#
# For example, a server that simply displays "hello" as the response for any
# request is implemented as follows:
#
# ```inko
# import std.net.http.server (Handle, Request, Response, Server)
#
# type async Main {
#   fn async main {
#     Server.new(fn { recover App() }).start(8_000).or_panic
#   }
# }
#
# type App {}
#
# impl Handle for App {
#   fn pub mut handle(request: mut Request) -> Response {
#     Response.new.string('hello')
#   }
# }
# ```
#
# A `Server` is created using `Server.new` which takes a closure. This closure
# must return a value of `uni T` where `T` is some type that implements the
# `Handle` trait. This closure is called for every newly established connection,
# and the returned `Handle` value lives as long as the connection remains
# active.
#
# `Server.start` starts and binds the server to IPv4 address `0.0.0.0` using the
# given port number (8000 in this case). You can specify a custom IP address and
# port using `Server.start_ip`, or bind to a Unix domain socket using
# `Server.start_unix`.
#
# In this example `App` is our application and implements the `Handle` trait.
# This trait has one required method: `handle`, which takes a request and
# returns its response. The response body in this example is set to the string
# `hello`.
#
# For more details, refer to the documentation of the `Server` and `Handle`
# types.
#
# # TLS support
#
# By default a `Server` starts in plain-text mode. To use TLS, create a `Server`
# using `Server.new` as usual then call `Server.tls` to configure it for TLS
# connections. A single `Server` can't handle _both_ plain-text and TLS requests
# at the same time. If this is required, you'll need to create a dedicated
# `Server` for plain-text requests and a dedicated `Server` for TLS requests.
#
# # Keep-alive support
#
# A `Server` supports (and by default enables) support for HTTP keep-alive
# connections, and terminates them if they are idle for too long. The idle
# timeout defaults to 60 seconds and can be changed by setting
# `Server.idle_timeout` to a different value.
#
# If a request contains a body that isn't fully read, the connection _can't_ be
# reused and will instead be closed after the response is written to the client.
#
# # Middleware
#
# A common technique used by HTTP frameworks/servers is to build a pipeline of
# types that handle the request/response cycle, with the individual components
# commonly referred to as "middleware". Such pipelines are typically created
# ahead of time (e.g. when a connection is established), then reused.
#
# This module takes a more low-level approach, requiring you to explicitly
# call/use the appropriate methods/types where necessary. Some of the building
# blocks this module provides are:
#
# - `conditional_request`: adds support for conditional requests using the
#   `If-None-Match` and `If-Modified-Since` headers
# - `RangeRequest`: a type that adds support for range requests using the
#   `Range` and `If-Range` headers
# - `Directory`: a type for serving static files from a directory, complete with
#   the `Cache-Control` and `Content-Type` headers
# - `Request.same_origin?`: a method for protecting against CSRF requests
#
# # CSRF protection
#
# By default no protection against CSRF requests is provided. To guard against
# such requests, use `Request.same_origin?` in your `Handle.handle`
# implementation like so:
#
# ```inko
# impl Handle for App {
#   fn pub mut handle(request: mut Request) -> Response {
#     # This line should be added before any other code.
#     if !request.same_origin? { return Response.forbidden }
#
#     Response.new.string('hello')
#   }
# }
# ```
#
# # Logging
#
# The `Logger` type is used as a basic request logger, it _doesn't_ support
# custom log messages. You can use it as follows:
#
# ```inko
# import std.net.http.server (Handle, Logger, Request, Response, Server)
#
# type async Main {
#   fn async main {
#     let logger = Logger.new
#
#     Server.new(fn { recover App(logger.clone) }).start(8_000).or_panic
#   }
# }
#
# type App {
#   let @logger: Logger
# }
#
# impl Handle for App {
#   fn pub mut handle(request: mut Request) -> Response {
#     Response.new.string('hello')
#   }
#
#   fn pub mut response(request: mut Request, response: Response) -> Response {
#     @logger.log(request, response)
#     response
#   }
# }
# ```
#
# That is: you create a `Logger` using `Logger.new` _before_ calling
# `Server.new`, then clone it for each newly established connection. Logging the
# request/response is done by overriding the default implementation of
# `Handle.response` to log the request and response data just before we write
# the response.
#
# While logging the request in `Handle.handle` is also fine, moving this code
# into `Handle.response` means we _always_ log the request regardless of
# how/where the code returns from `Handle.handle`.
#
# # Signal handling
#
# A `Server` defines signal handlers for the following signals:
#
# - `SIGQUIT`: stops the server immediately
# - `SIGINT`: gracefully stops the server
# - `SIGTERM`: gracefully stops the server
#
# The time to wait for a graceful shutdown is controlled by the
# `Server.shutdown_wait_time`.
#
# Sending the `SIGINT` or `SIGTERM` signal twice results in an immediate
# shutdown of the server.
#
# # Routing
#
# Instead of requiring you to construct a complex data structure to use for
# determining how to route a request, routing is done by pattern matching
# against the value of `Request.target`. For example:
#
# ```inko
# import std.net.http.server (Handle, Request, Response, Server)
#
# type async Main {
#   fn async main {
#     Server.new(fn { recover App() }).start(8_000).or_panic
#   }
# }
#
# type App {}
#
# impl Handle for App {
#   fn pub mut handle(request: mut Request) -> Response {
#     match request.target {
#       case [] -> Response.new.string('Home')
#       case ['about'] -> Response.new.string('About')
#       case _ -> Response.not_found
#     }
#   }
# }
# ```
#
# Using this server, requests to `/` show "Home" as the response, while requests
# to `/about` show "About", while all other requests result in a 404 response.
#
# To also route according to the request method, match against the value of
# `Request.method`:
#
# ```inko
# import std.net.http.server (Get, Handle, Request, Response, Server)
#
# type async Main {
#   fn async main {
#     Server.new(fn { recover App() }).start(8_000).or_panic
#   }
# }
#
# type App {}
#
# impl Handle for App {
#   fn pub mut handle(request: mut Request) -> Response {
#     match request.target {
#       case [] -> {
#         match request.method {
#           case Get -> Response.new.string('Home')
#           case _ -> Response.only_allow([Get])
#         }
#       }
#       case ['about'] -> {
#         match request.method {
#           case Get -> Response.new.string('About')
#           case _ -> Response.only_allow([Get])
#         }
#       }
#       case _ -> Response.not_found
#     }
#   }
# }
# ```
#
# This example behaves the same as the previous example, except it only allows
# `GET` requests. Sending a different kind of request (e.g. a `POST` request)
# results in a 405 response with the correct `Allow` header value. The `Allow`
# header is populated based on the `std.net.http.Method` values passed to
# `Response.only_allow`. The `std.net.http.server` module provides the following
# methods to use so you don't have to explicitly use the `Method` type:
#
# - `std.net.http.server.Get`
# - `std.net.http.server.Head`
# - `std.net.http.server.Post`
# - `std.net.http.server.Put`
# - `std.net.http.server.Delete`
#
# Instead of placing the routing logic directly in the `handle` method, it's
# recommended to create a `route` method for the `Handle` type and place the
# routing logic in this method:
#
# ```inko
# import std.net.http.server (Get, Handle, Request, Response, Server)
#
# type async Main {
#   fn async main {
#     Server.new(fn { recover App() }).start(8_000).or_panic
#   }
# }
#
# type App {
#   fn mut route(request: mut Request) -> Response {
#     match request.target {
#       case [] -> {
#         match request.method {
#           case Get -> Response.new.string('Home')
#           case _ -> Response.only_allow([Get])
#         }
#       }
#       case ['about'] -> {
#         match request.method {
#           case Get -> Response.new.string('About')
#           case _ -> Response.only_allow([Get])
#         }
#       }
#       case _ -> Response.not_found
#     }
#   }
# }
#
# impl Handle for App {
#   fn pub mut handle(request: mut Request) -> Response {
#     route(request)
#   }
# }
# ```
#
# Using this approach it's easier to find where the routing logic is located,
# and makes it easier to modify the response using the various building blocks
# provided by this module (e.g. by adding support for conditional requests).
#
# # Error handling
#
# The implementation of `Handle.handle` is required to return a `Response`. This
# means that if you call a method that may produce an error (i.e. it returns a
# `Result[A, B]`), you need to somehow convert such values into valid `Response`
# values.
#
# The `Response` type defines the field `Response.error` as `Option[String]`,
# and is assigned using the `Response.error` method. You can use this field to
# attach error messages that _must not_ be exposed to users (as such errors may
# contain sensitive information) but _may_ be recorded somewhere (e.g. by
# logging the message).
#
# Recording error messages is best done in a custom implementation of
# `Handle.response` instead of in `Handle.handle`.
#
# # Static files
#
# Serving static files is done using the `Directory` type, removing the need for
# a dedicated server or HTTP proxy to serve static files. For more information,
# refer to the documentation of the `Directory` type.
#
# # Generating HTML
#
# Generating HTML is best done using the `std.html` module and the
# `Response.html` method. For example:
#
# ```inko
# import std.html (Html)
# import std.net.http.server (Handle, Request, Response, Server)
#
# type async Main {
#   fn async main {
#     Server.new(fn { recover App() }).start(8_000).or_panic
#   }
# }
#
# type App {}
#
# impl Handle for App {
#   fn pub mut handle(request: mut Request) -> Response {
#     Response.new.html(Html.new.then(fn (h) { h.p.text('Hello') }))
#   }
# }
# ```
#
# This server always responds with the body `<p>Hello</p>`. For more details,
# refer to the documentation of `std.html.Html`.
#
# # Connection hijacking
#
# The `Response` type supports hijacking of the underlying connection, allowing
# you to implement e.g. server-sent sevents or websockets. This is done using
# `Response.hijack`, which takes a closure and passes it the raw HTTP socket.
# Once the closure returns, the connection is closed:
#
# ```inko
# import std.net.http.server (Handle, Request, Response, Server)
#
# type async Main {
#   fn async main {
#     Server.new(fn { recover App() }).start(8_000).or_panic
#   }
# }
#
# type App {}
#
# impl Handle for App {
#   fn pub mut handle(request: mut Request) -> Response {
#     Response.new.hijack(fn (sock) {
#       let Ok(_) = sock.write('hello') else return
#     })
#   }
# }
# ```
#
# The hijacking API is still experimental and subject to change.
import std.array
import std.base64
import std.bytes (Bytes, IntoByteArray, Slice)
import std.bytes.parsers (CR, LF, int)
import std.clone (Clone)
import std.cmp (Equal, Ordering, max, min)
import std.compress.gzip (Encoder as Gzip)
import std.crypto.sha1 (Sha1)
import std.drop (drop)
import std.fmt (Format, Formatter)
import std.fs (Metadata)
import std.fs.file (ReadOnlyFile)
import std.fs.path
import std.hash (Hash, Hasher)
import std.int (Format as IntFormat)
import std.io (
  BufferedRead, BufferedReader, BufferedWriter, Error as IoError, LimitReader,
  Read, SeekFrom, Write, copy_using,
)
import std.iter (Iter, Stream)
import std.mime (Mime)
import std.multipart
import std.net.http (
  Body as RequestBody, CHUNKED, ChunkedWriter, Encoding, Etag, Header,
  HeaderMap, Limits, Method, ParseError, Parser, Reader, Request as RawRequest,
  Status, Version, quality_value,
)
import std.net.http.header.values (tokens)
import std.net.http.websocket (WEBSOCKET_KEY, WEBSOCKET_VERSION, Websocket)
import std.net.ip (IpAddress)
import std.net.socket (
  Deadline, Notifier as SocketNotifier, SendFile, Shutdown as ShutdownTrait,
  SocketAddress, TcpClient, TcpServer, UnixAddress, UnixClient, UnixServer,
)
import std.net.tls
import std.rand (Random)
import std.range (InclusiveRange)
import std.set (Set)
import std.signal (Signal)
import std.stdio (Stdout)
import std.string (StringBuffer, ToString)
import std.sync (AtomicBool, AtomicInt, Future, Promise)
import std.sys.net (SEND_FILE_SIZE)
import std.time (DateTime, Duration, ToInstant)
import std.uri (Host, Uri, Values)

let MAX_HEADER_VALUES = 16

fn copy_file_range[W: mut + Write[IoError]](
  buffer: mut ByteArray,
  file: mut ReadOnlyFile,
  socket: mut W,
  range: InclusiveRange,
) -> Bool {
  if file.seek(SeekFrom.Start(range.start)).error? { return false }

  let from = LimitReader.new(file, limit: range.size)

  copy_using(buffer, from, socket, SEND_FILE_SIZE).ok?
}

# An alias for `std.net.http.Method.Get`.
fn pub inline Get -> Method {
  Method.Get
}

# An alias for `std.net.http.Method.Head`.
fn pub inline Head -> Method {
  Method.Head
}

# An alias for `std.net.http.Method.Post`.
fn pub inline Post -> Method {
  Method.Post
}

# An alias for `std.net.http.Method.Put`.
fn pub inline Put -> Method {
  Method.Put
}

# An alias for `std.net.http.Method.Delete`.
fn pub inline Delete -> Method {
  Method.Delete
}

# A method for handling conditional requests.
#
# This method takes a request and existing response and turns the response in a
# conditional response based on the request headers. A `Response` is made
# conditional if:
#
# 1. Its body is a `Body.File`
# 1. The response status is 200 OK
# 1. The request method is a safe method (per RFC 9110 section 9.2.1)
# 1. The request specifies the `If-None-Match` or `If-Modified-Since` header
#
# This method automatically generates an ETag for the response. Currently it
# uses strong etags based on the file size and modification time, but this may
# change in the future and shouldn't be relied upon (i.e. the tag should be
# treated as an opaque value).
#
# If a `Response` can't be made conditional, it's returned as-is.
#
# # Examples
#
# ```inko
# import std.net.http.server (
#   Handle, Request, Response, Server, conditional_request,
# )
#
# type async Main {
#   fn async main {
#     Server.new(fn { recover App() }).start(8_000).or_panic
#   }
# }
#
# type App {
#   fn route(request: mut Request) -> Response {
#     Response.new.string('hello')
#   }
# }
#
# impl Handle for App {
#   fn pub mut handle(request: mut Request) -> Response {
#     conditional_request(request, route(request))
#   }
# }
# ```
fn pub conditional_request(
  request: ref Request,
  response: Response,
) -> Response {
  if !request.method.safe? { return response }

  let meta = match response.body {
    case File(f) -> f.meta
    case _ -> return response
  }

  # Our ETags are treated as strong etags because the combination of
  # size+modification time is accurate enough, and weak ETags aren't effective
  # enough (e.g. they can't be used with `If-Range` headers).
  let tag = Etag.from_metadata(meta)
  let mtime = meta.modified_at.to_date_time
  let response = response.header(Header.etag, tag.to_string).header(
    Header.last_modified,
    mtime.to_rfc2822,
  )

  # Per RFC 9110 section 13.1.3, If-None-Match takes precedence over
  # If-Modified-Since.
  let cached = match request.headers.get(Header.if_none_match) {
    case Ok('*') -> true
    case Ok(v) -> Etag.parse_list(v).any?(fn (v) { v == tag })
    case _ -> {
      match request.headers.get(Header.if_modified_since) {
        case Ok(v) -> {
          match DateTime.from_rfc2822(v) {
            # The modification time may include nanoseconds but the time
            # format format doesn't include nanoseconds, hence we compare the
            # result to `DateTime.to_int` which doesn't include nanoseconds.
            case Some(v) -> mtime.to_int <= v.to_int
            case _ -> false
          }
        }
        case _ -> false
      }
    }
  }

  if cached {
    let status = match request.method {
      case Get or Head -> Status.not_modified
      case _ -> Status.precondition_failed
    }

    response.status(status).without_body
  } else {
    response
  }
}

fn inline parse_accept_range(
  input: Slice[String],
  size: Int,
) -> Option[InclusiveRange] {
  match input.split_once('-') {
    # "123-" means "starting at byte 123, up to and including the end".
    case Some((v, '')) -> {
      let start = try int(v)
      let end = size - 1

      if start <= size { Option.Some(start.to(end)) } else { Option.None }
    }
    # "-123" means "the last 123 bytes".
    case Some(('', v)) -> {
      let tail = try int(v)
      let end = size - 1
      let start = max(0, end - tail)

      if tail > 0 { Option.Some(start.to(end)) } else { Option.None }
    }
    case Some((a, b)) -> {
      let start = try int(a)
      let end = min(size - 1, try int(b))

      if start <= end { Option.Some(start.to(end)) } else { Option.None }
    }
    case _ -> Option.None
  }
}

fn parse_accept_ranges(
  input: Slice[String],
  file_size: Int,
  limit: Int,
) -> Option[Array[InclusiveRange]] {
  let ranges: Array[InclusiveRange] = []

  for range in input.split(',') {
    if ranges.size == limit { return Option.None }

    match (parse_accept_range(range.trim, file_size), ranges.last) {
      case (Some(r), Some(l)) if r.start > l.end -> ranges.push(r)
      case (Some(r), None) -> ranges.push(r)
      case _ -> return Option.None
    }
  }

  Option.Some(ranges)
}

# A method for handling range requests.
#
# When combined with the `conditional_request` method, the conditional response
# must be generated _first_ and used as the input for this method, not the other
# way around.
#
# If a client specifies multiple `Range` headers, only the first header is used.
# If there are too many ranges, they are not in ascending order or they overlap,
# a 416 Range Not Satisfiable response is returned.
#
# # Requirements
#
# For a range request to be supported, the following requirements must be met:
#
# 1. The request method must be GET or HEAD
# 1. The status of the initial response must be 200 OK
# 1. The initial response must be a file response created using `Response.file`,
#    with its body set to a `Body.File`
#
# # Settings
#
# By default the maximum number of ranges allowed in the `Range` header is 8.
# To change this value, use `RangeRequest.limit`.
#
# # Examples
#
# ```inko
# import std.net.http.server (Handle, RangeRequest, Request, Response, Server)
#
# type async Main {
#   fn async main {
#     Server.new(fn { recover App(RangeRequest.new) }).start(8_000).or_panic
#   }
# }
#
# type App {
#   let @range: RangeRequest
#
#   fn route(request: mut Request) -> Response {
#     Response.new.string('hello')
#   }
# }
#
# impl Handle for App {
#   fn pub mut handle(request: mut Request) -> Response {
#     @range.handle(request, route(request))
#   }
# }
# ```
type pub copy RangeRequest {
  let mut @limit: Int

  # Returns a new `RangeRequest` with its default settings.
  fn pub static new -> Self {
    Self(limit: 8)
  }

  # Sets the maximum number of ranges allowed in the `Range` header to the given
  # value.
  fn pub move limit(limit: Int) -> Self {
    @limit = limit
    self
  }

  # Handles a range request.
  #
  # The `response` argument is the initial response produced by a request
  # handler. This method takes this response and either returns it as-is or
  # modifies it based on the `Range` header, if range requests are supported.
  fn pub handle(request: mut Request, response: Response) -> Response {
    # Range requests are only supported for GET requests with an initial OK
    # response.
    if !request.method.get? or !response.status.ok? { return response }

    # We only extract the size for now such that when we produce a 416 error and
    # remove the body, we don't try to drop the `File` that we'd still be
    # borrowing here.
    let size = match response.body {
      case File(f) -> f.meta.size
      case _ -> return response
    }

    response.headers.set(Header.accept_ranges, 'bytes')

    let ranges = match request.headers.get(Header.range) {
      case Ok(v) -> {
        match v.split_once('=') {
          case Some(('bytes', v)) -> v
          case _ -> return response
        }
      }
      case _ -> return response
    }

    let matches = match request.headers.get(Header.if_range) {
      case Ok(giv) if giv.starts_with?('W/"') or giv.starts_with?('"') -> {
        match response.headers.get(Header.etag) {
          case Ok(cur) -> giv == cur
          case _ -> false
        }
      }
      case Ok(giv) -> {
        match response.headers.get(Header.last_modified) {
          case Ok(cur) -> giv == cur
          case _ -> false
        }
      }
      case _ -> true
    }

    if !matches { return response }

    let ranges = match parse_accept_ranges(ranges, size, @limit) {
      case Some(ranges) if ranges.size > 0 -> ranges
      case _ -> {
        # RFC 9110 doesn't make it clear if the `Content-Type` header should be
        # removed or not in this case. Servers out there don't behave
        # consistently either. Here we take the simplest choice of just leaving
        # the header in place, along with any other content specific headers
        # that may be present.
        return response
          .status(Status.range_not_satisfiable)
          .header(Header.content_range, 'bytes */${size}')
          .empty_body
      }
    }

    let file = match response.body {
      case File(f) -> f
      case _ -> return response
    }

    let resp = match ranges {
      case [range] -> {
        let hval = 'bytes ${range.start}-${range.end}/${size}'

        file.ranges = FileRanges.Single(range)
        response.header(Header.content_range, hval)
      }
      case ranges -> {
        let boundary = multipart.boundary_separator(request.random)
        let hval = 'multipart/byteranges; boundary=${boundary}'

        file.ranges = FileRanges.Multiple(ranges, boundary)
        response.header(Header.content_type, hval)
      }
    }

    resp.status(Status.partial_content)
  }
}

impl Clone for RangeRequest {
  fn pub clone -> Self {
    self
  }
}

fn head_request(request: ref Request, response: Response) -> Response {
  match request.method {
    case Head -> {
      let header = Header.content_length

      match response.body.size {
        case Fixed(n) -> response.headers.set(header, n.to_string)
        case None -> response.headers.set(header, '0')
        case Chunked -> {}
      }

      response.without_body
    }
    case _ -> response
  }
}

# Dynamically compresses the response, if it's a dynamic HTML response or a
# static text-like file (HTML, CSS, JSON, etc).
#
# Files with the following MIME types and dynamic responses with the following
# content types are compressed:
#
# - `text/*` (`text/html`, `text/css`, etc)
# - `application/json`
#
# Compression is only applied if the client includes the `Accept-Encoding`
# header containing the value `gzip`. Other encodings (e.g. Brotli) aren't
# supported.
#
# This method should be the last method used in a middleware pipeline as it
# modifies the body such that e.g. a `BodyReader` is no longer able to read the
# body. Refer to `Response.stream` for more details and caveats about streaming
# responses.
#
# # Examples
#
# This servers all static files in a given directory, compressing those where
# relevant (e.g. HTML files):
#
# ```inko
# import std.env
# import std.net.http.server (
#   Directory, Handle, Request, Response, Server, compress_response,
# )
#
# type App {
#   let @directory: Directory
# }
#
# impl Handle for App {
#   fn pub mut handle(request: mut Request) -> Response {
#     let res = @directory.handle(request, request.path.to_slice)
#
#     compress_response(request, res)
#   }
# }
#
# type async Main {
#   fn async main {
#     let path = env.arguments.get(0).or('.').to_path.expand.or_panic
#
#     Server
#       .new(fn { recover App(directory: Directory.new(path.clone)) })
#       .start(8_000)
#       .or_panic
#   }
# }
# ```
fn pub compress_response(request: ref Request, response: Response) -> Response {
  # Don't bother with the rest if the client didn't request a supported encoding
  # format.
  if
    !request.accepted_encodings.any?(fn (enc) {
      enc.name.equals_while_ignoring_case?('gzip') and enc.quality > 0.0
    })
  {
    return response
  }

  match response.body {
    case File(file) -> {
      match file.mime_components {
        case Some(('text', _)) -> {}
        case Some(('application', 'json')) -> {}
        case _ -> return response
      }
    }
    case String(_) or Bytes(_) -> {
      match response.headers.get(Header.content_type) {
        case Ok(v) if v.starts_with?('text/') -> {}
        case Ok('application/json') -> {}
        case _ -> return response
      }
    }
    case _ -> return response
  }

  let body = response.body := Body.None

  response
    .header(Header.content_encoding, 'gzip')
    .header(Header.vary, 'accept-encoding')
    .stream(fn move (stream) {
      match body {
        case File({ @data = file }) -> {
          let enc = Gzip.new(stream)

          copy_using(stream.buffer, file, to: enc, size: SEND_FILE_SIZE).ok?
        }
        case String(v) -> Gzip.new(stream).write(v).ok?
        case Bytes(v) -> Gzip.new(stream).write(v).ok?
        case _ -> true
      }
    })
}

# A type for building an HTTP response.
type pub Response {
  # The HTTP status code.
  #
  # This defaults to 200 OK.
  let pub mut @status: Status

  # The response headers.
  let pub @headers: HeaderMap

  # The response body.
  let pub mut @body: Body

  # A closure to use for hijacking the connection.
  #
  # If a closure is provided, the response body is written first and then the
  # closure is called. Once the closure returns, the connection is closed.
  let pub mut @hijacker: Option[fn (mut Socket)]

  # An optional error message associated with this response.
  #
  # This message is not written as part of the response. Instead, it signals a
  # `Response` is created in response to some sort of internal error and is
  # meant to be logged in some way (if desired).
  let pub mut @error: Option[String]

  # Returns a new and empty `Response`.
  fn pub static new -> Self {
    Self(
      status: Status.ok,
      headers: HeaderMap.new,
      body: Body.String(''),
      hijacker: Option.None,
      error: Option.None,
    )
  }

  # Returns a new 404 error response.
  fn pub static not_found -> Self {
    new.status(Status.not_found)
  }

  # Returns a new 405 error response.
  #
  # The `methods` argument is used to populate the `Allow` header with a list of
  # allowed request methods.
  #
  # The returned `Response` doesn't have a body set.
  fn pub static only_allow(methods: Array[Method]) -> Self {
    let names = String.join(methods.into_iter.map(fn (v) { v.to_string }), ', ')

    new.status(Status.method_not_allowed).header(Header.allow, names)
  }

  # Returns a new 400 error response.
  #
  # The returned `Response` doesn't have a body set.
  fn pub static bad_request -> Self {
    new.status(Status.bad_request)
  }

  # Returns a new 403 error response.
  #
  # The returned `Response` doesn't have a body set.
  fn pub static forbidden -> Self {
    new.status(Status.forbidden)
  }

  # Returns a new 500 error response.
  #
  # The returned `Response` doesn't have a body set.
  fn pub static internal_server_error -> Self {
    new.status(Status.internal_server_error)
  }

  # Returns an HTTP 426 response instructing the client to upgrade the used
  # HTTP version.
  fn pub static upgrade_http_version -> Response {
    new
      .status(Status.upgrade_required)
      .header(Header.upgrade, 'HTTP/1.1')
      .header(Header.connection, 'Upgrade')
  }

  # Returns an `WebsocketResponse` for upgrading an HTTP connection to a
  # WebSocket connection.
  #
  # Refer to the documentation of the `WebsocketResponse` type for more details.
  #
  # # Examples
  #
  # ```inko
  # import std.net.http.server (Handle, Request, Response, Server)
  # import std.time (Duration)
  #
  # type Handler {}
  #
  # impl Handle for Handler {
  #   fn pub mut handle(request: mut Request) -> Response {
  #     Response.websocket(request).then(fn (sock) {
  #       # ...
  #     })
  #   }
  # }
  #
  # type async Main {
  #   fn async main {
  #     let srv = Server.new(fn { recover Handler() })
  #
  #     srv.shutdown_wait_time = Duration.from_secs(0)
  #     srv.start(8_000).or_panic
  #   }
  # }
  # ```
  fn pub static websocket(request: mut Request) -> WebsocketResponse {
    WebsocketResponse.new(request)
  }

  # Returns a server-sent event stream response.
  #
  # The stream remains open until the `producer` closure returns. To produce
  # events, the closure should call `Events.send` or `Events.comment` on the
  # `Events` type it receives as an argument.
  #
  # This method sets the `Cache-Control` header to `no-cache` to ensure proxies
  # don't buffer or cache the event stream output.
  #
  # # Examples
  #
  # ```inko
  # import std.net.http.server (Event, Handle, Request, Response, Server)
  #
  # type App {}
  #
  # impl Handle for App {
  #   fn pub mut handle(request: mut Request) -> Response {
  #     Response.new.events(fn (ev) { ev.send(Event.new('message', 'hello')) })
  #   }
  # }
  #
  # type async Main {
  #   fn async main {
  #     Server.new(fn { recover App() }).start(8_000).or_panic
  #   }
  # }
  # ```
  fn pub move events(producer: fn (Events[mut Socket])) -> Self {
    header(Header.content_type, 'text/event-stream')
      .header(Header.cache_control, 'no-cache')
      .hijack(fn move (sock) { producer.call(Events.new(sock)) })
  }

  # Assigns the given value to the header.
  #
  # This method is just a shortcut for using `HeaderMap.set` through the
  # `Response.headers` field.
  fn pub move header(header: Header, value: String) -> Self {
    @headers.set(header, value)
    self
  }

  # Removes all values assigned to the header.
  fn pub move without_header(header: Header) -> Self {
    @headers.remove_all(header)
    self
  }

  # Sets the status of `self` to the given `Status`.
  fn pub move status(status: Status) -> Self {
    @status = status
    self
  }

  # Sets the body of `self` to an empty `String`.
  fn pub move empty_body -> Self {
    string('')
  }

  # Removes the body of `self`.
  #
  # When writing the response, no `Content-Length` header is used.
  fn pub move without_body -> Self {
    @body = Body.None
    self
  }

  # Sets the body of `self` to the given `String`.
  #
  # When writing the response, the `Content-Length` header value is set to the
  # byte size of the `String`.
  fn pub move string(value: String) -> Self {
    @body = Body.String(value)
    self
  }

  # Sets the body of `self` to the given HTML.
  #
  # This method is best used with documents generated using `std.html.Html`.
  #
  # This method assumes the HTML is valid UTF-8 and sets the `Content-Type`
  # encoding accordingly.
  #
  # The `Content-Type` header value is set automatically, and the
  # `Content-Length` header value is set to the byte size of the HTML document.
  fn pub move html[T: IntoByteArray](value: move T) -> Self {
    @headers.set(Header.content_type, 'text/html; charset=utf-8')
    @body = Body.Bytes(value.into_byte_array)
    self
  }

  # Sets the body of `self` to the given XML.
  #
  # This method is best used with documents generated using `std.xml.Xml`.
  #
  # This method assumes the XML is valid UTF-8 and sets the `Content-Type`
  # encoding accordingly.
  #
  # The `Content-Type` header value is set automatically, and the
  # `Content-Length` header value is set to the byte size of the HTML document.
  fn pub move xml[T: IntoByteArray](value: move T) -> Self {
    @headers.set(Header.content_type, 'application/xml; charset=utf-8')
    @body = Body.Bytes(value.into_byte_array)
    self
  }

  # Sets the body of `self` to the given `ByteArray`.
  #
  # When writing the response, the `Content-Length` header value is set to the
  # size of the `ByteArray`.
  fn pub move bytes(value: ByteArray) -> Self {
    @body = Body.Bytes(value)
    self
  }

  # Sets the body of `self` to the given JSON.
  #
  # The `Content-Type` header value is set automatically, and the
  # `Content-Length` header value is set to the byte size of the JSON document.
  fn pub move json(value: String) -> Self {
    @headers.set(Header.content_type, 'application/json')
    @body = Body.String(value)
    self
  }

  # Sets the body of `self` to the file located at `path`.
  #
  # When writing the response, the `Content-Length` header value is set to the
  # size of the file.
  #
  # If a MIME type can be determined based on the file path, this method
  # automatically sets the `Content-Type` header.
  #
  # # Errors
  #
  # If the file can't be opened or its metadata can't be retrieved, an
  # `std.io.Error` error is returned.
  #
  # If the path points to anything but a file (a directory, symbolic link, etc),
  # the return value is an `std.io.Error.NotFound` error.
  fn pub move file(path: ref path.Path) -> Result[Self, IoError] {
    let file = try ReadOnlyFile.new(path)
    let meta = try file.metadata

    match meta.type {
      case File -> {}
      case _ -> throw IoError.NotFound
    }

    let mime = match path.extension.then(fn (v) { Mime.from_extension(v) }) {
      case Some(v) -> {
        @headers.set(Header.content_type, v.to_string)
        Option.Some(v)
      }
      case _ -> Option.None
    }

    @body = Body.File(
      File(data: file, mime: mime, meta: meta, ranges: FileRanges.None),
    )
    Result.Ok(self)
  }

  # Sets the closure as the closure to use for hijacking the connection after
  # writing the response.
  fn pub move hijack(function: fn (mut Socket)) -> Self {
    @body = Body.None
    @hijacker = Option.Some(function)
    self
  }

  # Sets the error message of `self` to the given `String`.
  fn pub move error(message: String) -> Self {
    @error = Option.Some(message)
    self
  }

  # Turns `self` into a streaming response, the body of which is produced by the
  # provided closure.
  #
  # When writing a streaming response, the `Transfer-Encoding` header is set to
  # `chunked`.
  #
  # The purpose of this method is to allow streaming of dynamic content, such as
  # compressed file responses. For server-sent events or websockets you should
  # use `Response.events` and `Response.websocket` instead.
  #
  # # Writing responses
  #
  # The `writer` argument is a closure that is given an output stream to write
  # its data to. The return value _must_ be `true` to keep the connection open,
  # and `false` in the event of an error to ensure the connection is closed.
  #
  # Because this closure outlives the scope it's created in, if you capture any
  # data local to surrounding scope you should capture it by moving using an `fn
  # move` closure.
  #
  # # Reading streaming bodies
  #
  # When reading a body of `self` through a `BodyReader`, no data is read as
  # there's no way to incrementally/lazily read data produced by these kind of
  # responses. This means that if you have a pipeline of middlewares, you should
  # avoid using this method unless you are certain there are no parent/outer
  # middlewares that will need to read the body (e.g. to mutate it in some way).
  #
  # # Examples
  #
  # ```inko
  # import std.net.http.server (Handle, Request, Response, Server)
  #
  # type App {}
  #
  # impl Handle for App {
  #   fn pub mut handle(request: mut Request) -> Response {
  #     Response.new.stream(fn (stream) { stream.write('hello').ok? })
  #   }
  # }
  #
  # type async Main {
  #   fn async main {
  #     Server.new(fn { recover App() }).start(8_000).or_panic
  #   }
  # }
  # ```
  fn pub move stream(writer: fn (mut StreamingBody) -> Bool) -> Self {
    @body = Body.Stream(writer)
    self
  }

  fn move write(socket: mut Socket, timeout: Duration, keep: Bool) -> Bool {
    let len = @body.size

    # If the Connection header is already set (e.g. when upgrading or switching
    # protocols), leave the existing value as-is.
    @headers.try_set(
      Header.connection,
      if keep { 'keep-alive' } else { 'close' },
    )
    @headers.set(Header.date, DateTime.utc.to_rfc2822)

    match len {
      case Fixed(n) -> @headers.set(Header.content_length, n.to_string)
      case Chunked -> @headers.set(Header.transfer_encoding, CHUNKED)
      case _ -> {}
    }

    socket.buffer.append('HTTP/1.1 ')
    socket.buffer.append(@status.to_string)
    socket.buffer.append(' \r\n')
    @headers.write_to(socket.buffer)
    socket.buffer.append('\r\n')

    socket.timeout_after = timeout

    if socket.write(socket.buffer).error? { return false }

    socket.buffer.clear

    let res = write_body(socket)

    socket.reset_deadline
    res
  }

  fn move write_body(socket: mut Socket) -> Bool {
    let buf = socket.buffer

    match @body {
      case None -> true
      case String(v) -> socket.write(v).ok?
      case Bytes(v) -> socket.write(v).ok?
      case File({ @data = f, @ranges = None }) -> socket.send_file(buf, f).ok?
      case File({ @data = f, @ranges = Single(range) }) -> {
        copy_file_range(buf, f, socket, range)
      }
      case
        File(
          {
            @data = file,
            @mime = mime,
            @meta = meta,
            @ranges = Multiple(ranges, boundary),
          },
        ) -> {
        let writer = ChunkedWriter.new(socket)
        let ctype = mime.map(fn (v) { v.to_string })
        let fsize = meta.size.to_string

        for range in ranges {
          buf.append('--')
          buf.append(boundary)

          match ref ctype {
            case Some(v) -> {
              buf.append('\r\nContent-Type: ')
              buf.append(v)
            }
            case _ -> {}
          }

          buf.append('\r\nContent-Range: bytes ')
          buf.append(range.start.to_string)
          buf.append('-')
          buf.append(range.end.to_string)
          buf.append('/')
          buf.append(fsize)
          buf.append('\r\n\r\n')

          if writer.write(buf).error? { return false }

          buf.clear

          if !copy_file_range(buf, file, mut writer, range) { return false }

          buf.append('\r\n')
        }

        buf.append('--')
        buf.append(boundary)
        buf.append('--')

        if writer.write(buf).error? { return false }

        buf.clear
        writer.finish.ok?
      }
      case Stream(f) -> {
        let body = StreamingBody(ChunkedWriter.new(socket))

        if f.call(body) { body.finish.ok? } else { false }
      }
    }
  }
}

# A type that represents the ranges of a file to send.
type pub inline enum FileRanges {
  # The file as a whole should be sent (i.e. there are no ranges).
  case None

  # A single range.
  case Single(InclusiveRange)

  # Multiple ranges, along with the multipart boundary string to use.
  case Multiple(Array[InclusiveRange], String)
}

# A file to send to the client.
type pub File {
  # The data of the file.
  let pub @data: ReadOnlyFile

  # The MIME type of the file, if one could be determined.
  let pub @mime: Option[Mime]

  # The metadata (e.g. the size) of the file.
  let pub @meta: Metadata

  # An optional list of ranges to send.
  let pub mut @ranges: FileRanges

  # Returns the MIME type's type and subtype, if a MIME type is present.
  fn pub mime_components -> Option[(Slice[String], Slice[String])] {
    match @mime {
      case Some({ @type = a, @subtype = b }) -> Option.Some((a.clone, b.clone))
      case _ -> Option.None
    }
  }
}

# The size of a body.
type pub copy enum BodySize {
  # The body doesn't have a size (i.e. there's no `Content-Length` or
  # `Transfer-Encoding` header).
  case None

  # The body has a fixed size.
  case Fixed(Int)

  # The body uses the chunked transfer encoding.
  case Chunked
}

# The body of a response.
type pub inline enum Body {
  # The response doesn't have a body and `Content-Length` header.
  case None

  # The body is a `String` and the `Content-Length` header value is set to the
  # byte size of the `String`.
  case String(String)

  # The body is a `ByteArray` and the `Content-Length` header value is set to
  # the size of the `ByteArray`.
  case Bytes(ByteArray)

  # The body is a read-only file.
  #
  # The `Metadata` is used to obtain the size of the file and is used to set the
  # `Content-Length` header's value. Consumers of a `Response` or `Body` may
  # also use this value (e.g. to calculate an ETag).
  #
  # When creating a `Body.File` it's expected that the file's cursor points to
  # the start of the file. If this isn't the case then the value of the
  # `Content-Length` header won't be correct.
  case File(File)

  # A chunked/streaming response.
  #
  # Using a `BodyReader` for this kind of body results in no data being read
  # through the `BodyReader`, as there's no way to lazily/incrementally read
  # data in this case, similar to responses for hijacked connections.
  case Stream(fn (mut StreamingBody) -> Bool)

  # Returns a `BodyReader` that can be used to read the body from `self`.
  #
  # `Body` doesn't implement `Read` directly due to its internal representation,
  # so a separate reader must be obtained using this method.
  #
  # If the body is a `Body.File` then reading will advance the file's cursor,
  # and rewinding it manually (uisng `ReadOnlyFile.seek`) is necessary if you
  # intend to read the same `Body` multiple times.
  fn pub mut reader -> BodyReader {
    BodyReader(body: self, offset: 0)
  }

  # Returns `true` if a body is present.
  fn pub present? -> Bool {
    match self {
      case None -> false
      case _ -> true
    }
  }

  # Returns the size of the body, if there is one.
  fn pub mut size -> BodySize {
    match self {
      case None -> BodySize.None
      case String(v) -> BodySize.Fixed(v.size)
      case Bytes(v) -> BodySize.Fixed(v.size)
      case File({ @meta = m, @ranges = None }) -> BodySize.Fixed(m.size)
      case File({ @ranges = Single(r) }) -> BodySize.Fixed(r.size)
      case File(_) or Stream(_) -> BodySize.Chunked
    }
  }
}

# A `Read` type for reading bytes from a `Body`.
#
# When reading from a `Body.File` with one or more ranges, `BodyReader.read`
# ignores these ranges and reads from the file directly.
type pub BodyReader {
  let @body: mut Body
  let mut @offset: Int

  fn mut read_bytes[B: Bytes](
    input: ref B,
    into: mut ByteArray,
    size: Int,
  ) -> Int {
    # We use Slice.checked because the `ByteArray` in `Body.Bytes` may be
    # mutated in between calls, potentially invalidating the slice range.
    let end = min(@offset + size, input.size)
    let slice = Slice.checked(input, @offset, end)
    let len = slice.size

    if len > 0 {
      into.append(slice)
      @offset += len
    }

    len
  }
}

impl Read[IoError] for BodyReader {
  fn pub mut read(into: mut ByteArray, size: Int) -> Result[Int, IoError] {
    match @body {
      case None -> Result.Ok(0)
      case String(v) -> Result.Ok(read_bytes(v, into, size))
      case Bytes(v) -> Result.Ok(read_bytes(v, into, size))
      case File(f) -> f.data.read(into, size)
      case Stream(_) -> Result.Ok(0)
    }
  }
}

# A TCP or Unix domain socket address.
type pub inline enum Address {
  # The address of an IP socket.
  case Ip(SocketAddress)

  # The address of a Unix domain socket.
  case Unix(UnixAddress)

  # Returns the host name as a `String`.
  #
  # For IP sockets the return value is the IP address _without_ the port number.
  # For Unix address it's a human-readable version of the address.
  #
  # # Examples
  #
  # ```inko
  # import std.net.http.server (Address)
  # import std.net.ip (IpAddress)
  # import std.net.socket (SocketAddress)
  #
  # Address
  #   .Ip(SocketAddress(ip: IpAddress.v4(127, 0, 0, 1), port: 1234))
  #   .host # => '127.0.0.1'
  # ```
  fn pub host -> String {
    match self {
      case Ip(v) -> v.ip.to_string
      case Unix(v) -> v.to_readable_string
    }
  }
}

impl ToString for Address {
  # Returns the address as a `String`.
  #
  # For IP sockets the return value includes both the IP address and port
  # number. For Unix address it's a human-readable version of the address.
  #
  # # Examples
  #
  # ```inko
  # import std.net.http.server (Address)
  # import std.net.ip (IpAddress)
  # import std.net.socket (SocketAddress)
  #
  # Address
  #   .Ip(SocketAddress(ip: IpAddress.v4(127, 0, 0, 1), port: 1234))
  #   .to_string # => '127.0.0.1:1234'
  # ```
  fn pub to_string -> String {
    match self {
      case Ip(v) -> v.to_string
      case Unix(v) -> v.to_readable_string
    }
  }
}

impl Clone for Address {
  fn pub clone -> Self {
    match self {
      case Ip(v) -> Address.Ip(v.clone)
      case Unix(v) -> Address.Unix(v.clone)
    }
  }
}

impl Equal for Address {
  fn pub ==(other: ref Self) -> Bool {
    match (self, other) {
      case (Ip(a), Ip(b)) -> a == b
      case (Unix(a), Unix(b)) -> a == b
      case _ -> false
    }
  }
}

impl Hash for Address {
  fn pub hash[H: mut + Hasher](hasher: mut H) {
    match self {
      case Ip(v) -> v.hash(hasher)
      case Unix(v) -> v.hash(hasher)
    }
  }
}

type inline enum SocketKind {
  case Plain(TcpClient)
  case Secure(tls.Server[TcpClient])
  case Unix(UnixClient)
}

impl Read[IoError] for SocketKind {
  fn pub mut read(into: mut ByteArray, size: Int) -> Result[Int, IoError] {
    match self {
      case Plain(v) -> v.read(into, size)
      case Secure(v) -> v.read(into, size)
      case Unix(v) -> v.read(into, size)
    }
  }
}

# A socket for reading requests and writing responses.
#
# A `Socket` supports plain TCP, TLS over TCP and Unix domain socket
# connections.
type pub inline Socket {
  # The buffered stream to read from.
  #
  # Buffering is done at the socket/connection level so that we don't lose
  # partially read data in between requests, or when upgrading connections.
  let @reader: BufferedReader[SocketKind, IoError]

  # An intermediate buffer to use when streaming responses.
  #
  # This field is public so it may be used when streaming e.g. a compressed file
  # to the socket, allowing the buffer to be reused between requests.
  let pub @buffer: ByteArray

  fn static new(reader: BufferedReader[SocketKind, IoError]) -> Self {
    Self(reader: reader, buffer: ByteArray.with_capacity(1024))
  }

  fn static plain(socket: TcpClient) -> Self {
    new(BufferedReader.new(SocketKind.Plain(socket)))
  }

  fn static secure(socket: tls.Server[TcpClient]) -> Self {
    new(BufferedReader.new(SocketKind.Secure(socket)))
  }

  fn static unix(socket: UnixClient) -> Self {
    new(BufferedReader.new(SocketKind.Unix(socket)))
  }

  fn address -> Result[Address, IoError] {
    let addr = match @reader.inner {
      case Plain(v) -> Address.Ip(try v.socket.peer_address)
      case Secure(v) -> Address.Ip(try v.socket.peer_address)
      case Unix(v) -> Address.Unix(try v.socket.local_address)
    }

    Result.Ok(addr)
  }

  fn server_name_equals_host?(host: String) -> Bool {
    # The Host header may contain the port number, but the SNI only contains the
    # host name.
    let host_without_port = match host.split_once(':') {
      case Some((host, _)) -> host
      case _ -> host.to_slice
    }

    let Secure(srv) = @reader.inner else return true
    let Some(sni) = srv.server_name else return true

    sni.equals?(host_without_port)
  }
}

impl ShutdownTrait for Socket {
  fn pub mut shutdown_read -> Result[Nil, IoError] {
    match @reader.inner {
      case Plain(v) -> v.socket.shutdown_read
      case Secure(v) -> v.socket.shutdown_read
      case Unix(v) -> v.socket.shutdown_read
    }
  }

  fn pub mut shutdown_write -> Result[Nil, IoError] {
    match @reader.inner {
      case Plain(v) -> v.socket.shutdown_write
      case Secure(v) -> v.socket.shutdown_write
      case Unix(v) -> v.socket.shutdown_write
    }
  }

  fn pub mut shutdown -> Result[Nil, IoError] {
    match @reader.inner {
      case Plain(v) -> v.socket.shutdown
      case Secure(v) -> v.socket.shutdown
      case Unix(v) -> v.socket.shutdown
    }
  }
}

impl Read[IoError] for Socket {
  fn pub mut read(into: mut ByteArray, size: Int) -> Result[Int, IoError] {
    @reader.read(into, size)
  }
}

impl BufferedRead[IoError] for Socket {
  fn mut fill_buffer -> Result[Int, IoError] {
    @reader.fill_buffer
  }

  fn mut read_buffer(into: mut ByteArray, size: Int) -> Int {
    @reader.read_buffer(into, size)
  }

  fn pub mut read_byte -> Result[Option[Int], IoError] {
    @reader.read_byte
  }

  fn pub mut peek -> Result[Option[Int], IoError] {
    @reader.peek
  }
}

impl Deadline for Socket {
  fn pub mut timeout_after=[T: ToInstant](deadline: ref T) {
    match @reader.inner {
      case Plain(v) -> v.timeout_after = deadline
      case Secure(v) -> v.timeout_after = deadline
      case Unix(v) -> v.timeout_after = deadline
    }
  }

  fn pub mut reset_deadline {
    match @reader.inner {
      case Plain(v) -> v.reset_deadline
      case Secure(v) -> v.reset_deadline
      case Unix(v) -> v.reset_deadline
    }
  }
}

impl Write[IoError] for Socket {
  fn pub mut write[B: Bytes](bytes: ref B) -> Result[Nil, IoError] {
    match @reader.inner {
      case Plain(v) -> v.write(bytes)
      case Secure(v) -> v.write(bytes)
      case Unix(v) -> v.write(bytes)
    }
  }

  fn pub mut flush -> Result[Nil, IoError] {
    Result.Ok(nil)
  }
}

impl SendFile[IoError] for Socket {
  fn pub mut send_file(
    buffer: mut ByteArray,
    file: mut ReadOnlyFile,
  ) -> Result[Int, IoError] {
    match @reader.inner {
      case Plain(v) -> v.send_file(buffer, file)
      case Secure(v) -> v.send_file(buffer, file)
      case Unix(v) -> v.send_file(buffer, file)
    }
  }
}

# State shared by the pool and its connections.
#
# This state is accessed frequently (i.e. possible several times per request).
# We use atomics instead of processes and messages to reduce the overhead of
# this as much as possible.
type inline SharedState {
  # A boolean indicating if the server is alive or not.
  let @alive: AtomicBool

  # The number of currently active connections.
  let @active_connections: AtomicInt

  fn static new -> Self {
    Self(alive: AtomicBool.new(true), active_connections: AtomicInt.new(0))
  }

  fn inline no_active_connections? -> Bool {
    @active_connections.load == 0
  }

  fn inline add_active {
    @active_connections.add(1)
  }

  # Reduces the number of active connections by one, returns `true` if this was
  # the last active connection.
  fn inline reduce_active -> Bool {
    @active_connections.sub(1) == 1
  }

  fn inline shutdown -> Bool {
    @alive.compare_and_swap(current: true, new: false)
  }

  fn inline alive? -> Bool {
    @alive.load
  }
}

impl Clone for SharedState {
  fn pub clone -> Self {
    Self(alive: @alive, active_connections: @active_connections)
  }
}

type async Pool {
  let @shared: SharedState
  let mut @waiter: Option[Promise[Nil]]

  fn static new -> (Self, Future[Nil], SharedState) {
    let shared = SharedState.new
    let (fut, prom) = Future.new
    let con = Self(
      shared: recover shared.clone,
      waiter: recover Option.Some(prom),
    )

    (con, fut, shared)
  }

  fn async mut all_connections_are_idle {
    notify_waiter
  }

  fn async mut shutdown(wait: Bool) {
    if @shared.shutdown {
      # The first time the shutdown signal is received.
      if !wait or @shared.no_active_connections? { notify_waiter }
    } else {
      # The second time the shutdown signal is received, stop immediately.
      notify_waiter
    }
  }

  fn mut notify_waiter {
    match @waiter := Option.None {
      case Some(v) -> v.set(nil)
      case _ -> {}
    }
  }
}

type inline enum ParseResult {
  # The request is valid.
  #
  # The arguments are:
  #
  # 1. The parsed request
  # 2. A boolean indicating if the connection should be kept alive or closed
  case Ok(RawRequest, Bool)

  # The request is invalid (e.g. it contains invalid syntax), but a response can
  # be written back.
  #
  # The connection is to be closed after writing the response.
  case Error(Response)

  # The connection was closed or parsing a request took too long, and we should
  # stop the connection on our side.
  case Close
}

type async Connection[H: mut + Handle] {
  let @pool: Pool
  let @shared: SharedState
  let @socket: Socket
  let @address: Address
  let @limits: Limits
  let @handler: H
  let @random: Random
  let @read_timeout: Duration
  let @idle_timeout: Duration
  let @write_timeout: Duration
  let @close_timeout: Duration

  fn async mut run {
    @shared.add_active

    while @shared.alive? {
      match parse_request {
        case Ok(raw_req, keep) -> {
          let req = Request.new(@address.clone, raw_req, @limits, @random)
          let resp = @handler.response(req, @handler.handle(req))

          # HEAD requests are always supported.
          let resp = head_request(req, resp)

          let hijacker = resp.hijacker := Option.None
          let keep = keep and req.body.consumed? and hijacker.none?
          let ok = resp.write(@socket, @write_timeout, keep)

          if ok and keep { next }

          if ok {
            match hijacker {
              case Some(f) -> return hijack_connection(f)
              case _ -> {}
            }
          }
        }
        case Error(resp) -> {
          let resp = @handler.invalid_request(resp)

          resp.write(@socket, @write_timeout, keep: false)
        }
        case Close -> {}
      }

      # We only reach this point in the event of an error, or a connection that
      # shouldn't be kept alive.
      break
    }

    close
  }

  fn mut parse_request -> ParseResult {
    let parser = Parser.new(Reader.new(@socket), @socket.buffer, @limits)

    # Wait until the first byte arrives. This way we don't also apply the idle
    # timeout to parsing of the request.
    @socket.timeout_after = @idle_timeout

    # Flag the connection is inactive so that we don't wait for it as part of
    # the shutdown sequence.
    reduce_active

    # We're just peeking and not parsing, so an error means the underlying IO
    # stream is broken (e.g. the connection is closed), at which point all we
    # can do is abort.
    let Ok(Some(_)) = parser.peek else {
      # We flag the connection as active again so the shutdown sequence doesn't
      # have to account for this case _not_ incrementing it.
      @shared.add_active
      return ParseResult.Close
    }

    # Make the connection active again so we _do_ wait for it as part of the
    # shutdown sequence.
    @shared.add_active
    @socket.timeout_after = @read_timeout

    let parsed = parser.request

    @socket.reset_deadline

    match parsed {
      case Ok(req) -> {
        let keep = match req.version {
          case { @major = 1, @minor = 1 } -> true
          case { @major = 1, @minor = 0 } -> false
          case { @major = 0 } -> {
            return ParseResult.Error(Response.upgrade_http_version)
          }
          case _ -> {
            return ParseResult.Error(
              Response.new.status(Status.http_version_not_supported),
            )
          }
        }

        # Per RFC 9112 section 3.2, the Host header must be specified exactly
        # once.
        #
        # If the TLS server name indicator is given it must also equal the Host
        # header.
        match req.headers.value(Header.host) {
          case Ok(Single(host)) if host.size > 0 -> {
            if @socket.server_name_equals_host?(host) {
              ParseResult.Ok(req, keep)
            } else {
              ParseResult.Error(Response.new.status(Status.misdirected_request))
            }
          }
          case _ -> ParseResult.Error(Response.bad_request)
        }
      }
      case Error(Read(TimedOut)) -> ParseResult.Close
      case Error(InvalidMethod) -> {
        ParseResult.Error(Response.new.status(Status.not_implemented))
      }
      case
        Error(
          MissingUri
            or InvalidUri(_)
            or InvalidVersion
            or InvalidHeader
            or InvalidChunk
            or InvalidStatus
            or StatusTooLarge
            or Read(_),
        ) -> {
        ParseResult.Error(Response.new.status(Status.bad_request))
      }
      case Error(InvalidTransferEncoding) -> {
        ParseResult.Error(Response.new.status(Status.not_implemented))
      }
      case Error(UriTooLarge) -> {
        ParseResult.Error(Response.new.status(Status.uri_too_long))
      }
      # This status is from RFC 6585.
      case Error(HeaderTooLarge or TooManyHeaders) -> {
        ParseResult.Error(
          Response.new.status(Status.request_header_fields_too_large),
        )
      }
      # EndOfInput is produced when the socket is closed while parsing, and
      # there's nothing we can do about that.
      #
      # BodyTooLarge is only produced when reading from the body which we
      # haven't done at this stage, so such errors can't occur here.
      case Error(EndOfInput or BodyTooLarge) -> ParseResult.Close
    }
  }

  fn mut hijack_connection(hijacker: fn (mut Socket)) {
    # Update the connection state _first_ so that during a graceful shutdown we
    # don't (potentially forever) wait for the hijacked connection to stop.
    reduce_active
    hijacker.call(@socket)
    close_socket
  }

  fn mut close {
    close_socket
    reduce_active
  }

  fn mut reduce_active {
    # A shutdown signal may be sent while one or more connections are active. If
    # we _just_ reduced the active count here then the server would wait until
    # the shutdown timeout expires, because there's nothing to wake it up
    # earlier.
    #
    # If the shutdown signal is received after this check then either the server
    # shuts down because all connections are idle, or if there are new active
    # connections they'll eventually reach this point again.
    if @shared.reduce_active and !@shared.alive? {
      @pool.all_connections_are_idle
    }
  }

  fn mut close_socket {
    # Shutdown the writing half so the client is aware that it can no longer
    # read data.
    let _ = @socket.shutdown_write

    # If we close immediately then the client might not have a chance to read
    # the response.
    @socket.timeout_after = @close_timeout

    # We don't care about the actual return value here as we just use the
    # read() to wait for some sort of acknowledgement from the network stack.
    let _ = @socket.read(into: @socket.buffer, size: 0)
  }
}

# A parsed request path.
type pub inline Path {
  let @components: Array[Slice[String]]

  # Returns a tuple containing two values: the first component, and a slice
  # containing all remaining components.
  fn pub split_first -> Option[(ref Slice[String], array.Slice[Slice[String]])] {
    @components.split_first
  }

  # Returns `true` if `self` starts with the given prefix.
  fn pub starts_with?(prefix: String) -> Bool {
    for (idx, given) in prefix.split('/').with_index {
      match @components.get(idx) {
        case Ok(v) if given == v -> {}
        case _ -> return false
      }
    }

    true
  }

  # Returns the components of `self` as a `std.array.Slice`.
  fn pub to_slice -> array.Slice[Slice[String]] {
    @components.to_slice
  }
}

# An error produced when parsing a URL encoded form.
type pub inline enum FormError {
  # An error produced while reading the request body.
  case Read(ParseError)

  # The `Content-Type` header is invalid (e.g. an invalid encoding is used).
  case InvalidContentType

  # The data is read but contains invalid syntax.
  case InvalidSyntax
}

impl Format for FormError {
  fn pub fmt(formatter: mut Formatter) {
    match self {
      case Read(v) -> formatter.tuple('Read').field(v).finish
      case InvalidContentType -> formatter.tuple('InvalidContentType').finish
      case InvalidSyntax -> formatter.tuple('InvalidSyntax').finish
    }
  }
}

impl Equal for FormError {
  fn pub ==(other: ref Self) -> Bool {
    match (self, other) {
      case (Read(a), Read(b)) -> a == b
      case (InvalidContentType, InvalidContentType) -> true
      case (InvalidSyntax, InvalidSyntax) -> true
      case _ -> false
    }
  }
}

impl ToString for FormError {
  fn pub to_string -> String {
    match self {
      case Read(v) -> v.to_string
      case InvalidContentType -> 'the input encoding is invalid'
      case InvalidSyntax -> 'the form syntax is invalid'
    }
  }
}

# An HTTP request.
#
# This type is a wrapper around `std.net.http.Request` and provides additional
# data useful when writing a server, such as the socket address.
type pub Request {
  # A connection-local random number generator.
  #
  # This `Random` instance is created when a connection is established.
  let pub @random: mut Random

  # The raw client address of the connection.
  #
  # This address isn't necessarily accurate. For example, if your application
  # sits behind an HTTP proxy then this value will be the address of the proxy
  # and not the client. A client may also be able to spoof the address.
  let pub @address: Address

  # The request data for which a response is to be produced.
  let pub @data: RawRequest

  # The parsed request URI.
  #
  # We parse the path once and store it here as it's likely to be used
  # frequently, removing the need for parsing it every time.
  #
  # If the requested path is not an absolute path, the components list is empty.
  let pub @path: Path

  # The limits to apply when parsing HTTP data.
  let @limits: Limits

  fn static new(
    address: Address,
    request: RawRequest,
    limits: Limits,
    random: mut Random,
  ) -> Self {
    let comp = if request.uri.path.absolute? {
      request.uri.path.components.skip(1).to_array
    } else {
      []
    }

    Self(
      address: address,
      data: request,
      path: Path(comp),
      limits: limits,
      random: random,
    )
  }

  # Parses the `Host` header into a `(host, port)` tuple.
  fn pub host -> (Slice[String], Option[Int]) {
    # Per RFC 9110, the Host header is required and requests without it are
    # rejected, so this won't panic.
    let raw = headers.get(Header.host).get

    match raw.split_once(':') {
      case Some((host, port)) -> (host, Int.parse(port, IntFormat.Decimal))
      case _ -> (raw.to_slice, Option.None)
    }
  }

  # Parses the request's `Content-Type` header into a `Mime` value.
  #
  # This method always parses the _first_ `Content-Type` header, should multiple
  # such headers be provided.
  fn pub content_type -> Option[Mime] {
    match headers.get(Header.content_type) {
      case Ok(v) -> Mime.parse(v)
      case _ -> Option.None
    }
  }

  # Parses a form request into a `std.uri.Values`.
  #
  # For GET and HEAD requests, this method parses the query string. For other
  # request methods, this method requires the `Content-Type` header to be set to
  # `application/x-www-form-urlencoded` and consumes the request body.
  #
  # If the query string component of the URI is empty (for GET and HEAD
  # requests), or the body is empty (for all other request methods), an empty
  # `Values` is returned. In this case the body _isn't_ consumed.
  #
  # # Memory usage
  #
  # When parsing the body as a form, the body is read into memory. For large
  # payloads (e.g. when uploading files), use `Request.parse_multipart` instead
  # as that allows for streaming of key-value pairs.
  #
  # The size limit on the body imposed by the `Limits` type applies to the
  # _encoded_ body size, i.e. for `a%20b` the body size is considered to be 5
  # and not 3 bytes.
  #
  # # Errors
  #
  # For GET and HEAD requests no error is ever returned, as all the necessary
  # data is already parsed and validated at this point. For other requests an
  # error is returned if any of the following is true:
  #
  # 1. The `Content-Type` header isn't set to
  #    `application/x-www-form-urlencoded`
  # 1. The `Content-Type` header specifies the `charset` parameter with a value
  #    other than `utf-8`
  # 1. The form data in the body uses invalid syntax
  # 1. Reading the body fails, such as due to a network error or when the HTTP
  #    body can't be parsed
  fn pub mut url_encoded_form -> Result[Values, FormError] {
    match method {
      case Get or Head -> return Result.Ok(uri.query.parse)
      case _ -> {
        let typ = match content_type {
          case Some(v) -> v
          case _ -> throw FormError.InvalidContentType
        }

        match (typ.type, typ.subtype, typ.charset) {
          case ('application', 'x-www-form-urlencoded', Some('utf-8') or None)
          -> {}
          case _ -> throw FormError.InvalidContentType
        }
      }
    }

    let buf = ByteArray.new

    try body.read_all(buf).map_error(fn (e) { FormError.Read(e) })

    match Values.parse(buf) {
      case Some(v) -> Result.Ok(v)
      case _ -> Result.Error(FormError.InvalidSyntax)
    }
  }

  # Parses a multipart form request.
  #
  # This method doesn't care about the request method used, only that the
  # `Content-Type` header is set to the correct value.
  #
  # For more information, refer to the documentation of the
  # `std.multipart.Multipart` type.
  #
  # # Error handling
  #
  # This method returns an error if any of the following is true:
  #
  # 1. The `Content-Type` header is not set to `multipart/form-data; boundary=X`
  #    where `X` is the boundary delimiter
  # 1. The `Content-Type` header specifies the `charset` parameter with a value
  #    other than `utf-8`
  #
  # Note that while this method enforces the `charset` parameter to either be
  # set to `utf-8` or be absent, individual form fields may still specify a
  # different `charset` parameter as part of their `Content-Type` headers.
  #
  # Due to the streaming nature of multipart forms, other errors may be produced
  # when reading fields.
  fn pub mut multipart_form -> Result[
    multipart.Multipart[mut RequestBody, ParseError],
    FormError,
  ] {
    let mime = match content_type {
      case Some(v) -> v
      case _ -> throw FormError.InvalidContentType
    }

    let boundary = match (mime.type, mime.subtype, mime.charset) {
      case ('multipart', 'form-data', Some('utf-8') or None) -> {
        match mime.get('boundary') {
          case Ok(v) if v.size > 0 -> v.to_string
          case _ -> throw FormError.InvalidContentType
        }
      }
      case _ -> throw FormError.InvalidContentType
    }

    let mp = multipart.Multipart.new(body, boundary)

    mp.header_size = @limits.header_size
    Result.Ok(mp)
  }

  # Parses the request's `Accept` header values (if any) into a list of
  # `std.mime.Mime` values.
  #
  # When encountering an invalid MIME type, it and any remaining MIME types are
  # ignored.
  #
  # To guard against unreasonably large `Accept` header values (in addition to
  # the limits applied when parsing requests), this method only parses up to 16
  # valid MIME types.
  #
  # # Quality values
  #
  # The returned `Array` is sorted such that the most preferred formats come
  # first, using the `q` parameter if present (aka the "quality value").
  #
  # While RFC 9110 states the `q` parameter is case-insensitive, this
  # implementation treats it as case-sensitive (i.e. it doesn't support `Q`). To
  # our knowledge nobody uses `Q` instead of `q` so this shouldn't pose any
  # issues.
  #
  # If the value of a `q` parameter is invalid, it's treated as a weight of
  # `0.0`. If the value is absent, the weight defaults to `1.0`.
  fn pub accepted_mime_types -> Array[Mime] {
    let mimes = headers
      .get_all(Header.accept)
      .flat_map(fn (v) { Mime.parse_list(v) })
      .take(MAX_HEADER_VALUES)
      .to_array

    mimes.sort_by(fn (a, b) {
      let mut a_val = quality_value(a.get('q').ok)
      let mut b_val = quality_value(b.get('q').ok)

      match b_val.cmp(a_val) {
        case Equal if a.type.equals?(b.type) -> {
          # `a/b, a/b;foo=bar` results in `a/b;foo=bar, a/b`
          if a.subtype.equals?(b.subtype) {
            return b.parameters.size.cmp(a.parameters.size)
          }

          # `text/*, text/plain` results in `text/plain, text/*`
          match (a.subtype, b.subtype) {
            case ('*', _) -> Ordering.Greater
            case (_, '*') -> Ordering.Less
            case _ -> b.parameters.size.cmp(a.parameters.size)
          }
        }
        case ord -> ord
      }
    })

    mimes
  }

  # Parses the request's `Accept-Encoding` header values into an iterator of
  # `std.net.http.Encoding` values, ordered by their quality values.
  #
  # When encountering an invalid value, it and any remaining values are ignored.
  #
  # To guard against unreasonably large `Accept-Encoding` header values, this
  # method only parses up to 16 valid values.
  #
  # Similar to `Request.accepted_mime_types`, this method treats the "q"
  # parameter as case-sensitive. Refer to its documenation for more details on
  # how quality values are handled.
  fn pub accepted_encodings -> AcceptEncodings {
    let params = headers.get_all(Header.accept_encoding).any?(fn (v) {
      v.contains?(';')
    })

    # The "q" parameter is quite rare for Accept-Encoding headers, and the
    # header itself is frequently used.
    #
    # If we're certain no "q" parameters are ever included we can avoid parsing
    # these parameters and sorting the list, reducing the amount of allocations
    # necessary.
    if params {
      let encs = headers
        .get_all(Header.accept_encoding)
        .flat_map(fn (v) { Encoding.parse_list(v) })
        .take(MAX_HEADER_VALUES)
        .to_array

      encs.sort
      AcceptEncodings.Eager(encs.into_iter)
    } else {
      let iter = headers
        .get_all(Header.accept_encoding)
        .flat_map(fn (v) { Encoding.parse_simple_list(v) })
        .take(MAX_HEADER_VALUES)

      AcceptEncodings.Lazy(iter)
    }
  }

  # Returns the components of the request path.
  #
  # This differs from `Request.path` in that it returns the components such that
  # they can be pattern matched against, instead of returning a `Path`.
  #
  # # Examples
  #
  # ```inko
  # import std.net.http (Status)
  # import std.net.http.server (Handle, Request, Response)
  #
  # type App {}
  #
  # impl Handle for App {
  #   fn pub mut handle(request: mut Request) -> Response {
  #     match request.target {
  #       case [] -> Response.new.string('home')
  #       case ['about'] -> Response.new.string('about')
  #       case _ -> Response.new.status(Status.not_found)
  #     }
  #   }
  # }
  # ```
  fn pub target -> ref Array[Slice[String]] {
    @path.components
  }

  # Returns the request method.
  fn pub method -> Method {
    @data.method
  }

  # Returns the HTTP version used by the request.
  fn pub version -> Version {
    @data.version
  }

  # Returns an immutable borrow of the request URI.
  fn pub uri -> ref Uri {
    @data.uri
  }

  # Returns an mutable borrow of the request headers.
  fn pub headers -> ref HeaderMap {
    @data.headers
  }

  # Returns a mutable borrow of the request body.
  fn pub mut body -> mut RequestBody {
    @data.body
  }

  # Returns `true` if `self` is a request for which the origin and target are
  # the same (i.e. it's not a cross-site request).
  #
  # This method uses the `Sec-Fetch-Site` header. If this header is missing the
  # `Origin` and `Host` headers are compared instead.
  #
  # If all these headers are missing then the return value is `true` instead of
  # `false`, as this means the browser in question is severely out of date.
  fn pub same_origin? -> Bool {
    if method.safe? { return true }

    match headers.get(Header.sec_fetch_site) {
      case Ok('same-origin' or 'none') -> true
      case Ok(_) -> false
      case _ -> origin_matches_host?
    }
  }

  # Returns `true` if the value of the `Origin` header matches the value of the
  # `Host` header.
  #
  # If the `Origin` header is missing then the return value is `true`.
  fn pub origin_matches_host? -> Bool {
    match headers.get(Header.origin) {
      case Ok(origin) -> {
        match (Uri.parse(origin), host) {
          case (Ok(o), (h, p)) -> o.host == Host.new(h) and o.port == p
          case _ -> false
        }
      }
      case _ -> true
    }
  }
}

# A type that handles a single request and produces its response.
trait pub Handle {
  # Handles an incoming request and produces its response.
  fn pub mut handle(request: mut Request) -> Response

  # A method called when a request can't be parsed, such as when its syntax is
  # invalid.
  #
  # The `response` argument is a default `Response` generated for the type of
  # error.
  #
  # The return value is the `Response` presented to the client. The default
  # implementation of this method returns the response as-is.
  fn pub mut invalid_request(response: Response) -> Response {
    response
  }

  # A method called before writing a response.
  #
  # This method is _only_ called if a request could be parsed, otherwise
  # `Handle.invalid_request` is called instead.
  #
  # This method allows customizing of `Response` values at the
  # application-level, such as by wrapping them in a layout or by adding extra
  # headers. It can also be used for logging requests along with their response.
  #
  # The default implementation of this method returns the `Response` as-is.
  fn pub mut response(request: mut Request, response: Response) -> Response {
    response
  }
}

type inline enum SocketServer {
  case Tcp(TcpServer)
  case Unix(UnixServer)

  fn mut notifier -> Option[uni SocketNotifier] {
    match self {
      case Tcp(s) -> s.notifier
      case Unix(s) -> s.notifier
    }
  }

  fn mut accept(
    config: mut Tls,
    timeout: Duration,
  ) -> Result[uni Socket, IoError] {
    let sock = match self {
      case Tcp(s) -> {
        let sock = recover try s.accept

        # If we encounter any TLS errors we'll drop the socket and move on to
        # the next one, as there's nothing we can do about such errors.
        let sock = match config {
          case Static(c) -> {
            sock.timeout_after = timeout

            recover {
              match tls.Server.new(recover sock, c.clone) {
                case Ok(v) -> Socket.secure(v)
                case _ -> throw IoError.ConnectionAborted
              }
            }
          }
          case Dynamic(fun) -> {
            sock.timeout_after = timeout

            let pending = recover {
              match tls.PendingServer.new(recover sock) {
                case Ok(v) -> v
                case _ -> throw IoError.ConnectionAborted
              }
            }

            let name = pending.server_name
            let Some(conf) = fun.call(name) else throw IoError.ConnectionAborted

            recover {
              match pending.into_server(recover conf) {
                case Ok(v) -> Socket.secure(v)
                case _ -> throw IoError.ConnectionAborted
              }
            }
          }
          case _ -> recover Socket.plain(sock)
        }

        sock.reset_deadline
        sock
      }
      case Unix(s) -> recover Socket.unix(try s.accept)
    }

    Result.Ok(sock)
  }

  fn address -> Result[Address, IoError] {
    match self {
      case Tcp(v) -> Result.Ok(Address.Ip(try v.local_address))
      case Unix(v) -> Result.Ok(Address.Unix(try v.local_address))
    }
  }
}

# A type for notifying a `Server` that it should shut down.
type pub async Notifier[H: mut + Handle] {
  let @pool: Pool
  let @notifier: SocketNotifier

  fn static new(pool: Pool, notifier: uni SocketNotifier) -> Self {
    Self(pool: pool, notifier: notifier)
  }

  # Notifies the connection pool (and thus the server) that it should shut down.
  #
  # The `wait` argument specifies if the server should shut down gracefully
  # (`true`) or immediately (`false`).
  fn pub async mut notify(wait: Bool) {
    @notifier.notify
    @pool.shutdown(wait)
  }
}

# A type that waits for a signal to arrive and notifies the server accordingly.
type async SignalWaiter[H: mut + Handle] {
  let @notifier: Notifier[H]
  let @signal: Signal

  fn static new(notifier: Notifier[H], signal: Signal) -> Self {
    Self(notifier: notifier, signal: signal)
  }

  fn async immediate_shutdown {
    @signal.wait
    @notifier.notify(wait: false)
  }

  fn async graceful_shutdown {
    @signal.wait
    @notifier.notify(wait: true)

    # For graceful shutdown signals we support sending the signal twice to shut
    # down immediately.
    immediate_shutdown
  }
}

type pub inline enum Tls {
  case None
  case Static(tls.ServerConfig)
  case Dynamic(fn (Option[String]) -> Option[tls.ServerConfig])
}

# An HTTP server that handles incoming requests.
type pub Server[H: mut + Handle] {
  let @handler: fn -> uni H
  let @shared: SharedState
  let @pool: Pool
  let @waiter: Future[Nil]

  # The limitations to apply/enforce when parsing HTTP messages.
  let pub mut @limits: Limits

  # The maximum amount of time a connection is allowed to be idle for before
  # it's terminated.
  #
  # This timeout applies until the first byte is received, after which the
  # `Server.read_timeout` timeout is applied.
  #
  # This defaults to 60 seconds.
  let pub mut @idle_timeout: Duration

  # The maximum amount of time that can be spent parsing a request.
  #
  # This defaults to 5 seconds.
  let pub mut @read_timeout: Duration

  # The maximum amount of time that can be spent on writing a response.
  #
  # This defaults to 5 seconds.
  let pub mut @write_timeout: Duration

  # The maximum amount of time to wait for a client to acknowledge a connection
  # shutdown.
  #
  # When a connection is to be closed we don't do so immediately, but instead
  # wait a little while to allow clients to read any responses before observing
  # the disconnect.
  #
  # This value should be less than the value of `Server.shutdown_wait_time` to
  # ensure connections are in fact shut down gracefully.
  #
  # This defaults to 5 seconds.
  let pub mut @close_timeout: Duration

  # The maximum amount of time to wait as part of a graceful shutdown.
  #
  # This defaults to 10 seconds.
  let pub mut @shutdown_wait_time: Duration

  # The TLS/HTTPS configuration to use, if any.
  #
  # By default this configuration is absent and the protocol is plain HTTP. When
  # this value _is_ present, the protocol is automatically turned into HTTPS.
  let mut @tls: Tls

  # If the server should shut down in response to certain Unix signals.
  let pub mut @handle_signals: Bool

  # A closure to call before starting the server.
  #
  # The `Address` argument is the local address of the server.
  let mut @before_start: Option[fn (uni Address, Notifier[H])]

  # A closure to call when the server is about to shut down.
  #
  # This closure is called _before_ waiting for all connections to finish,
  # unless an error is produced in the server's `accept()` loop.
  let mut @before_shutdown: Option[fn]

  # Returns a new `Server` that serves requests using the provided handler.
  #
  # The `handler` argument is a unique closure that returns some owned value
  # that implements the `Handle` trait. This closure is called for each new
  # connection (_not_ for each request), producing a chain of `Handle` types to
  # call for each incoming request.
  fn pub static new(handler: fn -> uni H) -> Self {
    let (pool, waiter, shared) = Pool.new

    Self(
      shared: shared,
      pool: pool,
      waiter: waiter,
      handler: handler,
      limits: Limits.new,
      tls: Tls.None,
      idle_timeout: Duration.from_secs(60),
      read_timeout: Duration.from_secs(5),
      write_timeout: Duration.from_secs(5),
      close_timeout: Duration.from_secs(5),
      shutdown_wait_time: Duration.from_secs(10),
      handle_signals: true,
      before_shutdown: Option.None,
      before_start: Option.None,
    )
  }

  # Enables the use of TLS using the given `std.net.tls.ServerConfig`.
  #
  # The configuration is used for all connections, regardless of the server name
  # indicator value used as part of the TLS handshake. To use different
  # configurations per server name, configure TLS using `Server.dynamic_tls`
  # instead.
  fn pub mut tls(config: tls.ServerConfig) {
    @tls = Tls.Static(config)
  }

  # Enables the use of TLS using a configuration based on the server name
  # indicator.
  #
  # The provided closure is called every time a new TLS connection is
  # established and is given the name of the server as specified by the client's
  # hello message.
  #
  # Note that the server name indicator may be left out by the client (e.g. when
  # they connect using an IP address instead of a DNS name), so the closure
  # should take this into account and provide some sort of fallback
  # configuration for such cases.
  #
  # The return value is an optional `uni std.net.tls.ServerConfig` to use for
  # the connection. If an `Option.None` is returned the connection is aborted.
  fn pub mut dynamic_tls(fun: fn (Option[String]) -> Option[tls.ServerConfig]) {
    @tls = Tls.Dynamic(fun)
  }

  # Stores the given closure to be called before the server shuts down
  # gracefully.
  fn pub mut before_shutdown(function: fn) {
    @before_shutdown = Option.Some(function)
  }

  # Stores the given closure to be called before the server starts.
  fn pub mut before_start(function: fn (uni Address, Notifier[H])) {
    @before_start = Option.Some(function)
  }

  # Binds the server to IP address `0.0.0.0` (i.e. any IPv4 address) and the
  # given port, then starts it.
  #
  # To specify a custom IP address, use `Server.start_ip` instead.
  #
  # For more information, refer to the documentation of `Server.start_ip`.
  fn pub move start(port: Int) -> Result[Nil, IoError] {
    run(SocketServer.Tcp(try TcpServer.new(IpAddress.v4(0, 0, 0, 0), port)))
  }

  # Binds the server to the given IP address and port, then starts it.
  #
  # This method blocks the caller until the server stops.
  #
  # The port argument is always used as-is, even when a TLS configuration is
  # specified. This means that for TLS servers you should explicitly set the
  # port to 443, unless of course you _want_ to use a different port.
  fn pub move start_ip(ip: IpAddress, port: Int) -> Result[Nil, IoError] {
    run(SocketServer.Tcp(try TcpServer.new(ip, port)))
  }

  # Binds the server to the given Unix domain socket path and starts it.
  #
  # This method blocks the caller until the server stops.
  #
  # The socket file is removed when returning from this method, though it may be
  # left behind in the event of a panic. Abstract Unix domain sockets are
  # created by using a `Path` that starts with `\0` (e.g.
  # `'\0socket-name'.to_path`).
  fn pub move start_unix(path: ref path.Path) -> Result[Nil, IoError] {
    let res = run(SocketServer.Unix(try UnixServer.new(path)))
    let _ = path.remove_file

    res
  }

  fn move run(socket: SocketServer) -> Result[Nil, IoError] {
    let addr = recover try socket.address
    let notifier = Notifier.new(@pool, socket.notifier.get)

    if @handle_signals {
      SignalWaiter.new(notifier, Signal.Quit).immediate_shutdown
      SignalWaiter.new(notifier, Signal.Interrupt).graceful_shutdown
      SignalWaiter.new(notifier, Signal.Terminate).graceful_shutdown
    }

    match @before_start.as_mut {
      case Some(f) -> f.call(addr, notifier)
      case _ -> {}
    }

    loop {
      let client = match socket.accept(@tls, @read_timeout) {
        case Ok(v) -> v
        # ConnectionAborted may be produced if a connection is established and
        # then aborted _just_ before we get to accept it.
        case Error(ConnectionAborted) -> next
        # Interrupted is produced when we need to shut down.
        case Error(Interrupted) -> break
        case Error(e) -> throw e
      }

      # Not being able to obtain the peer address is pretty much unheard of at
      # this point, but _just_ in case it happens we simply skip the connection
      # and close it.
      let addr = recover {
        match client.address {
          case Ok(v) -> v
          case _ -> next
        }
      }

      handle(client, addr)
    }

    # Drop the socket as soon as possible so the backlog doesn't fill up with
    # new connections while we wait for existing ones to shut down.
    drop(socket)

    match @before_shutdown {
      case Some(f) -> f.call
      case _ -> {}
    }

    @waiter.get_until(@shutdown_wait_time)
    Result.Ok(nil)
  }

  fn mut handle(socket: uni Socket, address: uni Address) {
    Connection(
      shared: recover @shared.clone,
      pool: @pool,
      socket: socket,
      address: address,
      limits: recover @limits.clone,
      handler: recover @handler.call,
      idle_timeout: @idle_timeout,
      read_timeout: @read_timeout,
      write_timeout: @write_timeout,
      close_timeout: @close_timeout,
      random: recover Random.new,
    )
      .run
  }
}

type async LogWriter {
  let @output: Stdout

  fn static new -> Self {
    Self(recover Stdout.new)
  }

  fn async mut write(message: String) {
    let _ = @output.print(message)
  }
}

# A basic request/response logger.
#
# Output is written to STDOUT, using a dedicated process to allow for concurrent
# writes.
#
# To use a `Logger`, create one once _before_ creating a `Server`, then clone it
# using `Logger.clone` for every new connection. This ensures that all
# connections use the same underlying writer, preventing concurrent writes from
# messing up the STDOUT output.
type pub Logger {
  let @writer: LogWriter

  # If timestamps should be included for each log message.
  #
  # This defaults to `true`.
  let pub mut @time: Bool

  # If logging is enabled or not.
  #
  # This defaults to `true`.
  let pub mut @enabled: Bool

  # Returns a `Logger` using its default settings.
  fn pub static new -> Self {
    Self(writer: LogWriter.new, time: true, enabled: true)
  }

  # Logs a request along with its response.
  fn pub log(request: ref Request, response: ref Response) {
    if !@enabled { return }

    let addr = request.address
    let meth = request.method
    let ver = request.version
    let prev = request.headers.get(Header.referer).or('-').escaped
    let agent = request.headers.get(Header.user_agent).or('-').escaped
    let status = response.status
    let time = if @time { '${DateTime.utc.to_iso8601}: ' } else { '' }

    let path = request.uri.path.to_string.to_byte_array

    if request.uri.query.size > 0 {
      path.append('?')
      path.append(request.uri.query.to_string)
    }

    @writer.write(
      '${time}${addr.host} ${meth} ${path} HTTP/${ver} ${status} "${prev}" "${agent}"',
    )
  }
}

impl Clone for Logger {
  fn pub clone -> Self {
    Self(writer: @writer, time: @time, enabled: @enabled)
  }
}

type copy enum CacheControlState {
  case Disabled
  case Public
  case Private
}

# A type for generating the value of a `Cache-Control` response header.
#
# # Examples
#
# ```inko
# import std.net.http.server (CacheControl)
#
# CacheControl
#   .new
#   .max_age(Duration.from_secs(10))
#   .no_store
#   .to_string # => 'public, no-store, max-age=10, must-revalidate'
# ```
type pub inline CacheControl {
  let mut @max_age: Option[Duration]
  let mut @state: CacheControlState
  let mut @no_store: Bool
  let mut @no_transform: Bool
  let mut @must_revalidate: Bool
  let mut @proxy_revalidate: Bool

  # Returns a new `CacheControl` with its default settings.
  #
  # The defaults are as follows:
  #
  # - `max-age`: 30 days
  # - `must-revalidate`: `true`
  # - `public`: `true`
  fn pub static new -> Self {
    Self(
      max_age: Option.Some(Duration.from_secs(30 * 86_400)),
      must_revalidate: true,
      state: CacheControlState.Public,
      no_store: false,
      no_transform: false,
      proxy_revalidate: false,
    )
  }

  # Sets the `max-age` directive to the given `Duration`.
  fn pub move max_age(duration: Duration) -> Self {
    @max_age = Option.Some(duration)
    self
  }

  # Disables the `must-revalidate` directive.
  fn pub move no_revalidate -> Self {
    @must_revalidate = false
    self
  }

  # Enables the `no-cache` directive.
  fn pub move no_cache -> Self {
    @state = CacheControlState.Disabled
    self
  }

  # Enables the `no-store` directive.
  fn pub move no_store -> Self {
    @no_store = true
    self
  }

  # Enables the `no-transform` directive.
  fn pub move no_transform -> Self {
    @no_transform = true
    self
  }

  # Enables the `private` directive.
  #
  # This automatically disables the `public` and `no-cache` directives.
  fn pub move private -> Self {
    @state = CacheControlState.Private
    self
  }

  # Enables the `proxy-revalidate` directive.
  fn pub move proxy_revalidate -> Self {
    @proxy_revalidate = true
    self
  }
}

impl ToString for CacheControl {
  fn pub to_string -> String {
    let start = match @state {
      case Disabled -> return 'no-cache'
      case Public -> 'public'
      case Private -> 'private'
    }

    let buf = StringBuffer.new

    buf.push(start)

    if @no_store { buf.push(', no-store') }

    match @max_age {
      case Some(v) -> {
        buf.push(', max-age=')
        buf.push(v.to_secs.to_int.to_string)
      }
      case _ -> {}
    }

    if @must_revalidate { buf.push(', must-revalidate') }

    if @proxy_revalidate { buf.push(', proxy-revalidate') }

    if @no_transform { buf.push(', no-transform') }

    buf.into_string
  }
}

# A type for serving static files from a directory.
#
# This type supports conditional requests (e.g. using the `If-None-Match`
# header), HEAD requests, and range requests (using the `RangeRequest`
# type).
#
# If a request path resolves to a non-existing file, an HTTP 404 response with
# an empty body is returned. If the file does exist but couldn't be opened for
# some reason (e.g. due to insufficient file permissions), an HTTP 500 response
# with an empty body is returned and its `error` field is set to the underlying
# error's message.
#
# # Directory index files
#
# If the client requests a directory (e.g. `/foo`) and this directory contains
# an `index.html` file, the file's contents are served as if the file was
# requested directly. This allows clients to use both `/foo` and
# `/foo/index.html` to access the same data.
#
# # Caching
#
# Requests handled by this type automatically include a `Cache-Control` header.
# Its default value is `public, max-age=2592000, must-revalidate` and can be
# changed using the `Directory.cache_control` method.
#
# Caching is disabled for responses with the following content types:
#
# - text/html
# - text/xml
# - application/atom+xml
# - application/rss+xml
#
# The reason for this is that these types of files are typically updated
# frequently and as such should always be fresh. Due to the presence of ETags a
# client can still avoid downloading the entire body when the content hasn't
# changed.
#
# # Security
#
# This type guards against path traversal attacks. This is done by taking the
# user supplied path, joining it to the source path, expanding it to the real
# path (resolving components such as `..` in the process), and then checking if
# it's still in the source directory.
#
# # Examples
#
# This example serves all files from the current working directory:
#
# ```inko
# import std.env
# import std.net.http.server (Directory, Handle, Request, Response, Server)
#
# type async Main {
#   fn async main {
#     let dir = env.working_directory.or_panic
#
#     Server
#       .new(fn { recover App(Directory.new(dir.clone)) })
#       .start(8000)
#       .or_panic
#   }
# }
#
# type App {
#   let @directory: Directory
# }
#
# impl Handle for App {
#   fn pub mut handle(request: mut Request) -> Response {
#     match request.target {
#       case (Get, []) -> Response.new.string('home')
#       case (Get or Head, path) -> @directory.handle(request, path.to_slice)
#       case _ -> Response.not_found
#     }
#   }
# }
# ```
type pub inline Directory {
  # The path to the directory to serve files from.
  let pub @path: path.Path

  # The value of the `Cache-Control` header.
  #
  # We store this as a `String` instead of a `CacheControl` value such that we
  # only need to generate it once, instead of per request.
  let mut @cache_control: String

  # The type to use for handling range requests.
  let @range: RangeRequest

  # Returns a new `Directory` that serves files from the directory the absolute
  # path points to.
  #
  # # Panics
  #
  # This method panics if the `path` argument isn't an absolute path or if the
  # path points to a non-existing directory.
  #
  # Absolute paths are required to guard against path traversal attacks. This
  # method doesn't expand the path automatically such that this can be done
  # ahead of time, instead of this being done on a per connection basis.
  fn pub static new(path: path.Path) -> Self {
    if path.relative? { panic('the path must be absolute') }

    if !path.directory? {
      panic("${path} doesn't point to an existing directory")
    }

    Self(
      path: path,
      cache_control: CacheControl.new.to_string,
      range: RangeRequest.new,
    )
  }

  # Sets the `Cache-Control` header according to the settings of the
  # `CacheControl` value.
  fn pub move cache_control(value: CacheControl) -> Self {
    @cache_control = value.to_string
    self
  }

  # Serves a static file from the source directory.
  #
  # The `request` argument is the `Request` to return a `Response` for.
  #
  # The `components` argument is a `std.array.Slice` containing the parsed (i.e.
  # URI decoded) URI path components of the file to serve.
  fn pub handle(
    request: mut Request,
    components: array.Slice[Slice[String]],
  ) -> Response {
    let rel = components.iter.reduce(@path.clone, fn (p, c) { p.join(c) })

    # This ensures we can't read files outside of the directory.
    let Some(mut path) = @path.join_strict(rel) else return Response.not_found

    if path.directory? { path = path.join('index.html') }

    let resp = match Response.new.file(path) {
      case Ok(v) -> v
      case Error(NotFound) -> return Response.not_found
      case Error(e) -> return Response.internal_server_error.error(e.to_string)
    }

    let cache = match resp.body {
      case File(f) -> {
        match f.mime_components {
          case Some(('text', 'html' or 'xml')) -> false
          case Some(('application', 'atom+xml' or 'rss+xml')) -> false
          case _ -> true
        }
      }
      case _ -> false
    }

    resp.headers.set(
      Header.cache_control,
      if cache { @cache_control } else { 'no-cache' },
    )

    @range.handle(request, conditional_request(request, resp))
  }
}

impl Clone for Directory {
  fn pub clone -> Self {
    Self(path: @path.clone, cache_control: @cache_control, range: @range)
  }
}

# A type used for upgrading an HTTP connection to a WebSocket connection.
#
# # Defaults
#
# The defaults of a `WebsocketResponse` are as follows:
#
# - The list of protocols supported by the server is empty
# - The maximum number of client provided protocols considered is set to 8
#
# These defaults are changed using `WebsocketResponse.protocols` and
# `WebsocketResponse.max_protocols` respectively.
#
# # Extensions
#
# WebSocket extensions are not supported.
type pub inline WebsocketResponse {
  let @request: mut Request

  # The protocols supported by the server.
  let @protocols: Set[Slice[String]]

  # The maximum number of protocols as supplied by a client that are considered.
  #
  # If more protocols are specified these additional protocols are ignored.
  let mut @max_protocols: Int

  fn static new(request: mut Request) -> Self {
    Self(request: request, protocols: Set.new, max_protocols: 8)
  }

  # Adds the given protocols to the protocols supported by the server.
  fn pub move protocols(values: Array[String]) -> Self {
    for value in values { @protocols.insert(value.to_slice) }

    self
  }

  # Sets the maximum number of protocols considered to the given value.
  fn pub move max_protocols(value: Int) -> Self {
    @max_protocols = value
    self
  }

  # Performs the WebSocket handshake and returns a response.
  #
  # If the handshake succeeds then the response will hijack the HTTP connection
  # and turn it into a WebSocket connection. In this case the `body` argument is
  # called after writing the response headers and should be used for
  # reading/writing WebSocket messages.
  #
  # If the handshake fails an error response is returned, based on why the
  # handshake failed.
  fn pub move then(body: fn (mut Websocket[mut Socket])) -> Response {
    # Section 4.1 handshake requirement 2: the method must be GET and the
    # version at least 1.1.
    if !@request.method.get? { return Response.only_allow([Get]) }

    if @request.data.version < Version(1, 1) {
      return Response.upgrade_http_version
    }

    # Handshake requirements 5 and 6: Connection must contain "upgrade" and
    # Upgrade must be "websocket". Browsers (most notarbly Firefox) may also
    # include keep-alive in the "Connection" header, so we can't just check it
    # for equality.
    if
      !@request.headers.get(Header.connection).or('').split(',').any?(fn (v) {
        v.trim.equals_while_ignoring_case?('upgrade')
      })
    {
      return Response.bad_request
    }

    match @request.headers.get(Header.upgrade) {
      case Ok(v) if v.equals_while_ignoring_case?('websocket') -> {}
      case _ -> return Response.bad_request
    }

    # Requirement 7: the nonce must be 16 bytes encoded as base64, with padding.
    # This results in an encoded size of 24.
    let client_key = match @request.headers.get(Header.sec_websocket_key) {
      case Ok(v) if v.size == 24 -> v
      case _ -> return Response.bad_request
    }

    # Requirement 8: if the Origin header is present (= browsers), then it must
    # match the Host header value.
    if !@request.origin_matches_host? { return Response.forbidden }

    # Requirement 9: the version must match.
    match @request.headers.get(Header.sec_websocket_version) {
      case Ok(WEBSOCKET_VERSION) -> {}
      case _ -> {
        return Response
          .new
          .status(Status.upgrade_required)
          .header(Header.upgrade, 'websocket')
          .header(Header.connection, 'Upgrade')
          .header(Header.sec_websocket_version, WEBSOCKET_VERSION)
      }
    }

    # The RFC makes no mention of a limit applied to the number of protocols.
    # While we already limit the maximum size of header values, we still apply a
    # limit to the number of protocols so we don't waste time parsing large
    # values.
    let protocol = @request
      .headers
      .get_all(Header.sec_websocket_protocol)
      .flat_map(fn (v) { tokens(v) })
      .take(@max_protocols)
      .find(fn (v) { @protocols.contains?(v) })

    let accept = base64.encode(Sha1.hash(client_key + WEBSOCKET_KEY).bytes)
    let resp = Response
      .new
      .status(Status.switching_protocols)
      .header(Header.upgrade, 'websocket')
      .header(Header.connection, 'Upgrade')
      .header(Header.sec_websocket_accept, accept)

    # Notify the client about the protocol that we're using.
    match ref protocol {
      case Some(v) -> {
        resp.headers.set(Header.sec_websocket_protocol, v.to_string)
      }
      case _ -> {}
    }

    let rng = @request.random

    resp.hijack(fn move (socket) {
      let socket = Websocket.server(socket, rng, protocol.clone)

      body.call(socket)
    })
  }
}

# A stream of server-sent events.
type pub inline Events[T: mut + Write[IoError]] {
  let @stream: BufferedWriter[T, IoError]

  fn static new(stream: T) -> Self {
    Self(stream: BufferedWriter.new(stream))
  }

  # Sends an event to the client.
  #
  # The event's data is split into separate `data:` lines for each `\r\n`, `\n`
  # or `\r` sequence.
  #
  # # Examples
  #
  # ```inko
  # import std.net.http.server (Event, Handle, Request, Response, Server)
  #
  # type App {}
  #
  # impl Handle for App {
  #   fn pub mut handle(request: mut Request) -> Response {
  #     Response.new.events(fn (ev) { ev.send(Event.new('message', 'hello')) })
  #   }
  # }
  #
  # type async Main {
  #   fn async main {
  #     Server.new(fn { recover App() }).start(8_000).or_panic
  #   }
  # }
  # ```
  fn pub mut send[B: Bytes](event: Event[B]) -> Result[Nil, IoError] {
    if event.name.size > 0 {
      try @stream.write('event: ')
      try @stream.print(event.name)
    }

    match event.id {
      case Some(v) -> {
        try @stream.write('id: ')
        try @stream.print(v)
      }
      case _ -> {}
    }

    match event.retry {
      case Some(v) -> {
        try @stream.write('retry: ')
        try @stream.print(v.to_millis.to_string)
      }
      case _ -> {}
    }

    # Data may be terminated by \r\n, \n or _just_ a \r, so we have to split on
    # any of these sequences.
    let mut idx = 0
    let mut start = idx
    let max = event.data.size

    while idx < max {
      match event.data.get(idx).or_panic {
        case CR -> {
          try @stream.write('data: ')
          try @stream.print(Slice.new(event.data, start, idx))

          idx += 1

          if event.data.get(idx).or(-1) == LF { idx += 1 }

          start = idx
        }
        case LF -> {
          try @stream.write('data: ')
          try @stream.print(Slice.new(event.data, start, idx))
          idx += 1
          start = idx
        }
        case _ -> idx += 1
      }
    }

    if idx > start {
      try @stream.write('data: ')
      try @stream.print(Slice.new(event.data, start, idx))
    } else if idx == 0 {
      try @stream.print('data: ')
    }

    try @stream.write('\n')
    @stream.flush
  }

  # Sends a comment line to the client.
  #
  # Comments may be used as a keep-alive mechanism, though they may only be
  # useful when the response passes through one or more proxies.
  #
  # Note that this method _doesn't_ split the data into separate lines as the
  # SSE specification doesn't make it clear if this is supported or not, and if
  # so how the data should be split (e.g. there are no `data` fields for
  # comments). This means that `value` _shouldn't_ contain any line separators
  # as this could break the event stream.
  #
  # # Examples
  #
  # ```inko
  # import std.net.http.server (Handle, Request, Response, Server)
  #
  # type App {}
  #
  # impl Handle for App {
  #   fn pub mut handle(request: mut Request) -> Response {
  #     Response.new.events(fn (ev) { ev.comment('ping') })
  #   }
  # }
  #
  # type async Main {
  #   fn async main {
  #     Server.new(fn { recover App() }).start(8_000).or_panic
  #   }
  # }
  # ```
  fn pub mut comment[B: Bytes](value: ref B) -> Result[Nil, IoError] {
    try @stream.write(': ')
    try @stream.print(value)
    try @stream.write('\n')
    @stream.flush
  }
}

# A server-sent event.
type pub inline Event[B: Bytes] {
  let @name: String
  let @data: B
  let mut @id: Option[String]
  let mut @retry: Option[Duration]

  # Returns a new `Event`.
  #
  # The `name` argument is the name of the event. This can be an empty `String`
  # to leave out the event name.
  #
  # The `data` argument is the data to include in the event. This can be an
  # empty `String` or `ByteArray` to produce an event without any data.
  fn pub static new(name: String, data: B) -> Self {
    Self(name: name, data: data, id: Option.None, retry: Option.None)
  }

  # Sets the ID of `self` to the given value.
  #
  # # Examples
  #
  # ```inko
  # import std.net.http.server (Event, Handle, Request, Response, Server)
  #
  # type App {}
  #
  # impl Handle for App {
  #   fn pub mut handle(request: mut Request) -> Response {
  #     Response.new.events(fn (ev) {
  #       ev.send(Event.new('event', 'data').id('event-id'))
  #     })
  #   }
  # }
  #
  # type async Main {
  #   fn async main {
  #     Server.new(fn { recover App() }).start(8_000).or_panic
  #   }
  # }
  # ```
  fn pub move id(value: String) -> Self {
    @id = Option.Some(value)
    self
  }

  # Sets the time a client should wait before reconnecting if the connection is
  # lost.
  #
  # # Examples
  #
  # ```inko
  # import std.net.http.server (Event, Handle, Request, Response, Server)
  # import std.time (Duration)
  #
  # type App {}
  #
  # impl Handle for App {
  #   fn pub mut handle(request: mut Request) -> Response {
  #     Response.new.events(fn (ev) {
  #       ev.send(Event.new('event', 'data').retry(Duration.from_secs(5)))
  #     })
  #   }
  # }
  #
  # type async Main {
  #   fn async main {
  #     Server.new(fn { recover App() }).start(8_000).or_panic
  #   }
  # }
  # ```
  fn pub move retry(value: Duration) -> Self {
    @retry = Option.Some(value)
    self
  }
}

# An iterator over the values in the `Accept-Encoding` header.
type pub inline enum AcceptEncodings {
  case Lazy(Stream[Encoding])
  case Eager(array.IntoIter[Encoding])
}

impl Iter[Encoding] for AcceptEncodings {
  fn pub mut next -> Option[Encoding] {
    match self {
      case Lazy(v) -> v.next
      case Eager(v) -> v.next
    }
  }
}

# A stream to write a response body to without buffering it.
#
# This currently uses the chunked transfer-encoding mechanism of HTTP 1.1, but
# in the future may transparently handle the streaming differences between
# different HTTP versions.
type pub inline StreamingBody {
  let @writer: ChunkedWriter[mut Socket, IoError]

  # Returns a `ByteArray` that may be used as an intermediate buffer for a
  # `Reader` that produces output to be written to `self` (e.g. using
  # `std.io.copy_using`).
  fn pub mut buffer -> mut ByteArray {
    @writer.writer.buffer
  }

  fn move finish -> Result[Nil, IoError] {
    @writer.finish
  }
}

impl Write[IoError] for StreamingBody {
  fn pub mut write[B: Bytes](bytes: ref B) -> Result[Nil, IoError] {
    @writer.write(bytes)
  }

  fn pub mut flush -> Result[Nil, IoError] {
    @writer.flush
  }
}
