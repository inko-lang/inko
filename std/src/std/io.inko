# Types for core IO functionality.
#
# The IO module provides the basic building blocks for IO operations such as
# reading from and writing to a file.
import std.bytes (Bytes, Slice)
import std.cmp (Equal, min)
import std.drop (Drop)
import std.fmt (Format, Formatter)
import std.iter (Stream)
import std.libc
import std.ptr
import std.string (ToString)

# The initial number of bytes to read in `Read.read_all`
let INITIAL_READ_ALL_SIZE = 1024

# The maximum number of bytes to read when using `Read.read_all`.
let MAX_READ_ALL_SIZE = 1024 * 1024

# The default size of the buffer maintained by `BufferedReader`.
let READ_BUFFER_SIZE = 8 * 1024

# The default size of the buffer maintained by `BufferedWriter`.
let WRITE_BUFFER_SIZE = 8 * 1024

fn extern inko_process_start_blocking(process: Pointer[UInt8])

fn extern inko_process_stop_blocking(process: Pointer[UInt8])

fn invalid_buffer_size(size: Int) -> Never {
  panic('the buffer size (${size}) must be greater than zero')
}

# Signals the start of a C function call that may perform blocking IO
# operations.
#
# This method should be called immediately before a C function call that might
# block the current OS thread. It _must not_ be used for anything else.
#
# If this method is called multiple times in the same process, it is required
# for there to be an equal number of calls to `stop_blocking`. For example, this
# is OK:
#
# ```inko
# import std.io (start_blocking, stop_blocking)
#
# start_blocking
# start_blocking
# perform_c_function_call(...)
# stop_blocking
# stop_blocking
# ```
#
# # Examples
#
# ```inko
# import std.io (Error, start_blocking, stop_blocking)
#
# fn extern open(path: Pointer[UInt8], flags: Int32, ...) -> Int32
#
# start_blocking
#
# let fd = open('test.txt'.pointer, 0 as Int32, 0 as Int32)
# let err = stop_blocking
#
# if fd as Int == -1 {
#   panic('failed to open the file: ${Error.from_os_error(err)}')
# }
# ```
fn pub start_blocking {
  inko_process_start_blocking(_INKO.process)
}

# Signals the end of a C function call that may perform blocking IO operations.
#
# The return value is the value of `errno` as an `Int`. This value is read
# _before_ signalling the end of the blocking call, ensuring we read the value
# from the same thread the IO call is performed on.
#
# If `start_blocking` is called multiple times, this method _must_ be called the
# same number of times. In this case only the _last_ call may reschedule the
# current process. If a C function call mutates any global state, that state
# _must_ be retrieved before the final call to this method, as upon being
# rescheduled the current process may run on a different OS thread and thus read
# a different state.
fn pub stop_blocking -> Int {
  let err = libc.errno

  # If the operation took too long, this reschedules the current process. This
  # means that any global state read after this point may not be from the same
  # thread as the IO call is performed on.
  inko_process_stop_blocking(_INKO.process)
  err
}

fn reset_os_error {
  libc.errno_location.0 = 0 as Int32
}

# An error type for I/O operations.
#
# This type is typically constructed from raw OS error codes such as `ENOENT` on
# Unix systems. This enum doesn't define a constructor for every possible error.
# Instead, we define a constructor for the most commonly used errors, and
# represent other errors using the `Other` constructor.
type pub copy enum Error {
  # The address is already in use.
  case AddressInUse

  # The address isn't available.
  case AddressUnavailable

  # A connection is already established.
  case AlreadyConnected

  # A resource already exists.
  case AlreadyExists

  # The operation failed because a pipe was closed.
  case BrokenPipe

  # The connection was aborted by the remote server.
  case ConnectionAborted

  # The connection was refused by the remote server.
  case ConnectionRefused

  # The connection was reset by the remote server.
  case ConnectionReset

  # An operation would result in a deadlock.
  case Deadlock

  # A directory isn't empty.
  case DirectoryNotEmpty

  # A file is too large.
  case FileTooLarge

  # The remote host is unreachable.
  case HostUnreachable

  # The operation is in progress.
  case InProgress

  # The operation was interrupted.
  case Interrupted

  # One or more arguments are invalid.
  case InvalidArgument

  # The file name is invalid.
  case InvalidFileName

  # The seek operation is invalid.
  case InvalidSeek

  # The resource is a directory.
  case IsADirectory

  # The network is down.
  case NetworkDown

  # The resource isn't a directory.
  case NotADirectory

  # A connection isn't established.
  case NotConnected

  # The resource isn't found.
  case NotFound

  # The operation failed because not enough memory could be allocated.
  case OutOfMemory

  # The operation failed because it lacked the necessary privileges.
  case PermissionDenied

  # The filesystem is read-only.
  case ReadOnlyFilesystem

  # The resource is busy.
  case ResourceBusy

  # The underlying storage is full.
  case StorageFull

  # The operation timed out.
  case TimedOut

  # The operation would block.
  case WouldBlock

  # A memory address used (e.g. as an argument) is in an invalid range.
  case BadAddress

  # A file couldn't be renamed, linked or copied because the operation takes
  # places across different devices.
  case CrossDeviceLink

  # The operation isn't supported.
  case NotSupported

  # A file descriptor is invalid.
  case InvalidFileDescriptor

  # An error not covered by the other constructor.
  #
  # The wrapped `Int` is the raw error code.
  case Other(Int)

  # Returns an `Error` from a raw OS error code.
  fn pub static from_os_error(code: Int) -> Error {
    match code {
      case libc.EAGAIN -> Error.WouldBlock
      case libc.EPERM -> Error.PermissionDenied
      case libc.ENOENT -> Error.NotFound
      case libc.EINTR -> Error.Interrupted
      case libc.ENOMEM -> Error.OutOfMemory
      case libc.EACCES -> Error.PermissionDenied
      case libc.EBUSY -> Error.ResourceBusy
      case libc.EEXIST -> Error.AlreadyExists
      case libc.ENOTDIR -> Error.NotADirectory
      case libc.EISDIR -> Error.IsADirectory
      case libc.EINVAL -> Error.InvalidArgument
      case libc.EFBIG -> Error.FileTooLarge
      case libc.ENOSPC -> Error.StorageFull
      case libc.ESPIPE -> Error.InvalidSeek
      case libc.EROFS -> Error.ReadOnlyFilesystem
      case libc.EPIPE -> Error.BrokenPipe
      case libc.EDEADLK -> Error.Deadlock
      case libc.ENAMETOOLONG -> Error.InvalidFileName
      case libc.ENOTEMPTY -> Error.DirectoryNotEmpty
      case libc.ETIME -> Error.TimedOut
      case libc.EADDRINUSE -> Error.AddressInUse
      case libc.EADDRNOTAVAIL -> Error.AddressUnavailable
      case libc.ENETDOWN -> Error.NetworkDown
      case libc.ENETUNREACH -> Error.NetworkDown
      case libc.ECONNABORTED -> Error.ConnectionAborted
      case libc.ECONNRESET -> Error.ConnectionReset
      case libc.EISCONN -> Error.AlreadyConnected
      case libc.ENOTCONN -> Error.NotConnected
      case libc.ETIMEDOUT -> Error.TimedOut
      case libc.ECONNREFUSED -> Error.ConnectionRefused
      case libc.EHOSTUNREACH -> Error.HostUnreachable
      case libc.EINPROGRESS -> Error.InProgress
      case libc.EFAULT -> Error.BadAddress
      case libc.EXDEV -> Error.CrossDeviceLink
      case libc.ENOTSUP or libc.EOPNOTSUPP -> Error.NotSupported
      case libc.EBADF -> Error.InvalidFileDescriptor
      case val -> Error.Other(val)
    }
  }

  # Returns the last OS error produced by the current OS thread.
  fn pub static last_os_error -> Error {
    from_os_error(libc.errno)
  }
}

impl ToString for Error {
  fn pub to_string -> String {
    match self {
      case AddressInUse -> 'the address is already in use'
      case AddressUnavailable -> "the address isn't available"
      case AlreadyConnected -> 'the connection is already established'
      case AlreadyExists -> 'the resource already exists'
      case BrokenPipe -> 'the operation failed because a pipe was closed'
      case ConnectionAborted -> 'the connection was terminated by the server'
      case ConnectionRefused -> 'the connection was refused by the server'
      case ConnectionReset -> 'the connection was reset by the server'
      case Deadlock -> 'the resource would deadlock'
      case DirectoryNotEmpty -> "the directory isn't empty"
      case FileTooLarge -> 'the file is too large'
      case HostUnreachable -> 'the host is unreachable'
      case InProgress -> 'the operation is in progress'
      case Interrupted -> 'the operation was interrupted'
      case InvalidArgument -> 'one or more arguments are invalid'
      case InvalidFileName -> 'the file name is too long'
      case InvalidSeek -> 'the seek operation is invalid'
      case IsADirectory -> 'the resource is a directory'
      case NetworkDown -> 'the network is down'
      case NotADirectory -> "the resource isn't a directory"
      case NotConnected -> "a connection isn't established"
      case NotFound -> "the resource isn't found"
      case OutOfMemory -> 'we ran out of memory'
      case PermissionDenied -> 'the operation lacks the necessary privileges'
      case ReadOnlyFilesystem -> 'the file system is read-only'
      case ResourceBusy -> 'the resource is busy'
      case StorageFull -> 'the storage is full'
      case TimedOut -> 'the operation timed out'
      case WouldBlock -> 'the operation would block'
      case BadAddress -> 'a memory address is in an invalid range'
      case CrossDeviceLink -> {
        "the operation failed because it can't be performed across devices"
      }
      case NotSupported -> "the operation isn't supported"
      case InvalidFileDescriptor -> 'the file descriptor is invalid'
      case Other(code) -> 'an other error with code ${code} occurred'
    }
  }
}

impl Format for Error {
  fn pub fmt(formatter: mut Formatter) {
    let name = match self {
      case AddressInUse -> 'AddressInUse'
      case AddressUnavailable -> 'AddressUnavailable'
      case AlreadyConnected -> 'AlreadyConnected'
      case AlreadyExists -> 'AlreadyExists'
      case BrokenPipe -> 'BrokenPipe'
      case ConnectionAborted -> 'ConnectionAborted'
      case ConnectionRefused -> 'ConnectionRefused'
      case ConnectionReset -> 'ConnectionReset'
      case Deadlock -> 'Deadlock'
      case DirectoryNotEmpty -> 'DirectoryNotEmpty'
      case FileTooLarge -> 'FileTooLarge'
      case HostUnreachable -> 'HostUnreachable'
      case InProgress -> 'InProgress'
      case Interrupted -> 'Interrupted'
      case InvalidArgument -> 'InvalidArgument'
      case InvalidFileName -> 'InvalidFileName'
      case InvalidSeek -> 'InvalidSeek'
      case IsADirectory -> 'IsADirectory'
      case NetworkDown -> 'NetworkDown'
      case NotADirectory -> 'NotADirectory'
      case NotConnected -> 'NotConnected'
      case NotFound -> 'NotFound'
      case OutOfMemory -> 'OutOfMemory'
      case PermissionDenied -> 'PermissionDenied'
      case ReadOnlyFilesystem -> 'ReadOnlyFilesystem'
      case ResourceBusy -> 'ResourceBusy'
      case StorageFull -> 'StorageFull'
      case TimedOut -> 'TimedOut'
      case WouldBlock -> 'WouldBlock'
      case BadAddress -> 'BadAddress'
      case CrossDeviceLink -> 'CrossDeviceLink'
      case NotSupported -> 'NotSupported'
      case InvalidFileDescriptor -> 'InvalidFileDescriptor'
      case Other(code) -> {
        formatter.tuple('Other').field(code).finish
        return
      }
    }

    formatter.tuple(name).finish
  }
}

impl Equal for Error {
  fn pub ==(other: ref Error) -> Bool {
    match (self, other) {
      case (AddressInUse, AddressInUse) -> true
      case (AddressUnavailable, AddressUnavailable) -> true
      case (AlreadyConnected, AlreadyConnected) -> true
      case (AlreadyExists, AlreadyExists) -> true
      case (BrokenPipe, BrokenPipe) -> true
      case (ConnectionAborted, ConnectionAborted) -> true
      case (ConnectionRefused, ConnectionRefused) -> true
      case (ConnectionReset, ConnectionReset) -> true
      case (Deadlock, Deadlock) -> true
      case (DirectoryNotEmpty, DirectoryNotEmpty) -> true
      case (FileTooLarge, FileTooLarge) -> true
      case (HostUnreachable, HostUnreachable) -> true
      case (InProgress, InProgress) -> true
      case (Interrupted, Interrupted) -> true
      case (InvalidArgument, InvalidArgument) -> true
      case (InvalidFileName, InvalidFileName) -> true
      case (InvalidSeek, InvalidSeek) -> true
      case (IsADirectory, IsADirectory) -> true
      case (NetworkDown, NetworkDown) -> true
      case (NotADirectory, NotADirectory) -> true
      case (NotConnected, NotConnected) -> true
      case (NotFound, NotFound) -> true
      case (OutOfMemory, OutOfMemory) -> true
      case (PermissionDenied, PermissionDenied) -> true
      case (ReadOnlyFilesystem, ReadOnlyFilesystem) -> true
      case (ResourceBusy, ResourceBusy) -> true
      case (StorageFull, StorageFull) -> true
      case (TimedOut, TimedOut) -> true
      case (WouldBlock, WouldBlock) -> true
      case (Other(a), Other(b)) -> a == b
      case (CrossDeviceLink, CrossDeviceLink) -> true
      case (NotSupported, NotSupported) -> true
      case (InvalidFileDescriptor, InvalidFileDescriptor) -> true
      case _ -> false
    }
  }
}

# An error produced when reading an exact number of bytes.
type pub inline enum ReadExactError[E] {
  # More input is required from the input stream.
  case EndOfInput

  # An error that occurred while reading data from the input stream.
  case Read(E)
}

impl Format for ReadExactError if E: Format {
  fn pub fmt(formatter: mut Formatter) {
    match self {
      case EndOfInput -> formatter.tuple('EndOfInput').finish
      case Read(e) -> formatter.tuple('Read').field(e).finish
    }
  }
}

impl Equal for ReadExactError if E: Equal {
  fn pub ==(other: ref Self) -> Bool {
    match (self, other) {
      case (EndOfInput, EndOfInput) -> true
      case (Read(a), Read(b)) -> a == b
      case _ -> false
    }
  }
}

impl ToString for ReadExactError if E: ToString {
  fn pub to_string -> String {
    match self {
      case EndOfInput -> {
        'the end of the input stream is reached, but more input is required'
      }
      case Read(e) -> e.to_string
    }
  }
}

# A type data can be read from (e.g. a File).
trait pub Read[E] {
  # Reads up to `size` bytes from `self` into the given `ByteArray`, returning
  # the number of bytes read.
  #
  # The `into` argument is the `ByteArray` to read the bytes into. The capacity
  # of this `ByteArray` is increased automatically if necessary.
  #
  # The `size` argument specifies how many bytes are to be read.
  #
  # The return value is the number of bytes read.
  #
  # The number of bytes read may be less than `size`. This can happen for
  # different reasons, such as when all input is consumed or not enough data is
  # available (yet).
  fn pub mut read(into: mut ByteArray, size: Int) -> Result[Int, E]

  # Reads exactly `size` bytes into `into`.
  #
  # Whereas `Read.read` might return early if fewer bytes are available in the
  # input stream, `Read.read_exact` continues reading until the desired amount
  # of bytes is read.
  #
  # # Errors
  #
  # If the end of the input stream is encountered before filling the buffer, an
  # `Error.EndOfInput` error is returned.
  #
  # If an error is returned, no assumption can be made about the state of the
  # `into` buffer, i.e. there's no guarantee data read so far is in the buffer
  # in the event of an error.
  fn pub mut read_exact(
    into: mut ByteArray,
    size: Int,
  ) -> Result[Nil, ReadExactError[E]] {
    let mut pending = size

    while pending > 0 {
      match read(into, pending) {
        case Ok(0) if pending > 0 -> throw ReadExactError.EndOfInput
        case Ok(n) -> pending -= n
        case Error(e) -> throw ReadExactError.Read(e)
      }
    }

    Result.Ok(nil)
  }

  # Reads from `self` into the given `ByteArray`, returning when all input is
  # consumed.
  #
  # The return value is the number of bytes read.
  #
  # # Errors
  #
  # This method returns an `Error` if the underlying call to `Read.read` returns
  # an `Error`.
  fn pub mut read_all(bytes: mut ByteArray) -> Result[Int, E] {
    let mut total = 0
    let mut read_size = INITIAL_READ_ALL_SIZE

    loop {
      match read(into: bytes, size: read_size) {
        case Ok(0) -> return Result.Ok(total)
        case Ok(n) -> {
          total += n

          # To reduce the number of calls to `Reader.read` when there's lots of
          # input to consume, we increase the read size if deemed beneficial.
          if read_size < MAX_READ_ALL_SIZE and n == read_size { read_size *= 2 }
        }
        case Error(e) -> throw e
      }
    }
  }
}

trait WriteInternal {
  # Performs a single raw write to the underlying stream.
  fn mut write_internal(data: Pointer[UInt8], size: Int) -> Result[Int, Error]

  # Writes all the data to the underlying stream.
  fn mut write_all_internal(
    data: Pointer[UInt8],
    size: Int,
  ) -> Result[Nil, Error] {
    let mut rem = size
    let mut src = data

    while rem > 0 {
      match write_internal(src, rem) {
        case Ok(n) -> {
          rem -= n
          src = ptr.add(src, n)
        }
        case Error(e) -> return Result.Error(e)
      }
    }

    Result.Ok(nil)
  }
}

# A type data can be written to (e.g. a File).
trait pub Write[E] {
  # Writes the entirety of `bytes` to the underlying stream.
  #
  # Types implementing this method must guarantee that upon returning from this
  # method, either all of the data is written and a `Ok(Nil)` is returned, _or_
  # an `Error` is returned.
  fn pub mut write[B: Bytes](bytes: ref B) -> Result[Nil, E]

  # Writes the entirety of `bytes` to the underlying stream, followed by
  # a Unix newline.
  fn pub mut print[B: Bytes](bytes: ref B) -> Result[Nil, E] {
    try write(bytes)
    write('\n')
  }

  # Flushes any pending writes to the file system.
  #
  # Flushing writes is a potentially expensive operation, and unnecessarily
  # calling this method may degrade performance.
  #
  # When flushing data to disk it's important to remember that the actual
  # behaviour may vary based on the type of file system, operating system and
  # storage hardware that's used. In particular, it's possible for one of these
  # components to say "Yup, I totally flushed the data, you're all good!" when
  # in fact they have not fully flushed the data.
  fn pub mut flush -> Result[Nil, E]
}

# Trait for seeking to a given offset in a stream of bytes.
trait pub Seek[E] {
  # Seeks to the given byte offset, returning the new offset.
  #
  # If `position` is negative, seeking is performed in reverse order relative to
  # the end.
  fn pub mut seek(position: Int) -> Result[Int, E]
}

# A `Read` type using an internal buffer, allowing more efficient reading and
# additional operations.
trait pub BufferedRead[E]: Read[E] {
  # Fills the internal buffer by reading from the underlying stream.
  #
  # Upon success, this method returns `Ok(n)` where `n` is the number of bytes
  # remaining in the buffer. If the underlying read fails, an `Error` is
  # returned.
  #
  # If there are bytes remaining in the buffer, calls to this method shouldn't
  # modify it.
  fn mut fill_buffer -> Result[Int, E]

  # Reads up to `size` bytes from the internal buffer into `into`, returning the
  # number of bytes read.
  #
  # If the buffer relies on a cursor, the cursor must be advanced by this method
  # such that multiple calls to `read_buffer` don't read the same bytes.
  fn mut read_buffer(into: mut ByteArray, size: Int) -> Int

  # Read and return a single byte.
  #
  # If a byte is read, `Ok(Some(n))` is returned where `n` is the byte. A
  # `Ok(None)` indicates the end of the input.
  #
  # # Examples
  #
  # ```inko
  # import std.io (Buffer, BufferedReader)
  #
  # let buffer = Buffer.new('hello')
  # let reader = BufferedReader.new(buffer)
  #
  # reader.read_byte # => Result.Ok(Option.Some(104))
  # reader.read_byte # => Result.Ok(Option.Some(101))
  # ```
  fn pub mut read_byte -> Result[Option[Int], E]

  # Reads the current byte from the buffer, without consuming it from the
  # underlying buffer.
  #
  # If a byte is read, `Ok(Some(n))` is returned where `n` is the byte. A
  # `Ok(None)` indicates the end of the input.
  #
  # # Examples
  #
  # ```inko
  # import std.io (Buffer, BufferedReader)
  #
  # let buffer = Buffer.new('hello')
  # let reader = BufferedReader.new(buffer)
  #
  # reader.peek # => Result.Ok(Option.Some(104))
  # reader.peek # => Result.Ok(Option.Some(104))
  # ```
  fn pub mut peek -> Result[Option[Int], E]

  # Read bytes into `into` up to and including the byte specified in the `byte`
  # argument.
  #
  # The `inclusive` argument specifies if the `byte` value should also be read
  # into the `ByteArray`, or if it should be discarded.
  #
  # Upon success, the return value is `Ok(n)` where `n` is the number of bytes
  # read from the input stream. If `inclusive` is set to `false`, `n` still
  # accounts for the terminal byte. That is, if the input is `abc` and the
  # terminal byte is `c`, then the returned size is 3 bytes.
  #
  # # Examples
  #
  # Reading until and including a given byte:
  #
  # ```inko
  # import std.io (Buffer, BufferedReader)
  #
  # let reader = BufferedReader.new(Buffer.new('hello\nworld'))
  # let bytes = ByteArray.new
  #
  # reader.read_until(byte: 0xA, into: bytes, inclusive: true) # => Result.Ok(6)
  # bytes.to_string # => 'hello\n'
  # ```
  #
  # Excluding the byte from the buffer:
  #
  # ```inko
  # import std.io (Buffer, BufferedReader)
  #
  # let reader = BufferedReader.new(Buffer.new('hello\nworld'))
  # let bytes = ByteArray.new
  #
  # reader.read_until(byte: 0xA, into: bytes, inclusive: false) # => Result.Ok(6)
  # bytes.to_string # => 'hello'
  # ```
  fn pub mut read_until(
    byte: Int,
    into: mut ByteArray,
    inclusive: Bool,
  ) -> Result[Int, E] {
    let mut total = 0

    loop {
      match try read_byte {
        case Some(val) if byte == val -> {
          if inclusive { into.push(val) }

          total += 1
          break
        }
        case Some(val) -> {
          total += 1
          into.push(val)
        }
        case _ -> break
      }
    }

    Result.Ok(total)
  }

  # Read bytes into `into` up to and including the newline byte (0xA aka
  # `"\n"`).
  #
  # The `inclusive` argument specifies if the newline should also be read into
  # the `ByteArray`, or if it should be discarded.
  #
  # Upon success, the return value is `Ok(n)` where `n` is the number of bytes
  # read from the input stream. If `inclusive` is set to `false`, `n` still
  # accounts for the newline. That is, if the input is `ab\n`, then the returned
  # size is 3 bytes.
  #
  # # Examples
  #
  # Reading until and including the end of a line:
  #
  # ```inko
  # import std.io (Buffer, BufferedReader)
  #
  # let reader = BufferedReader.new(Buffer.new('hello\nworld'))
  # let bytes = ByteArray.new
  #
  # reader.read_line(into: bytes, inclusive: true) # => Result.Ok(6)
  # bytes.to_string # => 'hello\n'
  # ```
  #
  # Excluding the newline from the buffer:
  #
  # ```inko
  # import std.io (Buffer, BufferedReader)
  #
  # let reader = BufferedReader.new(Buffer.new('hello\nworld'))
  # let bytes = ByteArray.new
  #
  # reader.read_line(into: bytes, inclusive: false) # => Result.Ok(6)
  # bytes.to_string # => 'hello'
  # ```
  fn pub mut read_line(into: mut ByteArray, inclusive: Bool) -> Result[Int, E] {
    read_until(byte: 0xA, into: into, inclusive: inclusive)
  }

  # Returns an iterator that yields the bytes in `self`.
  #
  # Each byte is wrapped in a `Result`, as reading may fail.
  #
  # # Examples
  #
  # ```inko
  # import std.fs.file (ReadOnlyFile)
  # import std.io (BufferedReader)
  #
  # let file = ReadOnlyFile.new('README.md').get
  # let reader = BufferedReader.new(file)
  #
  # reader.bytes.next # => Option.Some(Result.Ok(35))
  # ```
  fn pub move bytes -> Stream[Result[Int, E]] {
    Stream.new(fn move {
      match read_byte {
        case Ok(Some(num)) -> Option.Some(Result.Ok(num))
        case Ok(None) -> Option.None
        case Error(err) -> Option.Some(Result.Error(err))
      }
    })
  }
}

# A type for performing buffered reads from a `Read` type.
#
# Using a `Read` type directly can be inefficient, as many calls to `Read.read`
# may involve many system calls. `BufferedReader` wraps a `Read` and buffers
# data into an internal buffer, reducing the total amount of system calls, at
# the cost of needing to maintain an in-memory buffer.
#
# # `BufferedReader` and sockets
#
# By default a `BufferedReader` reads exactly N bytes from the underlying `Read`
# type, where `N` is the capacity provided to `BufferedReader.with_capacity`.
# For sockets (e.g. a `TcpClient`) this may result in a call to
# `BufferedReader.read` blocking the calling process indefinitely if not enough
# input is available (e.g. the buffer size is 32 KiB but only 1 KiB of data is
# available through the socket).
#
# To prevent this from happening, you can set `BufferedReader.exact` to `false`
# (the default is `true`):
#
# ```inko
# import std.io (BufferedReader)
# import std.net.socket (TcpClient)
#
# fn example(socket: TcpClient) {
#   let buf = ByteArray.new
#   let reader = BufferedReader.new(socket)
#
#   reader.exact = false
#   reader.read(into: buf, size: 32).or_panic
# }
# ```
#
# When set to `false`, only a single `read` is performed when filling up the
# buffer, such that the calling process is never blocked for a potentially long
# amount of time. This makes it possible to use `BufferedReader` with a socket
# and get the expected results (i.e. no indefinite blocking `read` calls), at
# the cost of (potentially) more `read` calls compared to when `exact` is set to
# `true`.
type pub BufferedReader[T: mut + Read[E], E] {
  # The `Read` type to read data from.
  let pub @inner: T

  # If the amount of bytes to read into the buffer should be exactly the buffer
  # size, or if it can be less.
  let pub mut @exact: Bool

  # The buffer of data read from the internal `Read` type.
  let @buffer: ByteArray

  # The maximum amount of bytes to read from the internal `Read` type.
  let mut @capacity: Int

  # The current offset into the buffer of read bytes.
  let mut @offset: Int

  # Returns a new buffered reader that wraps the given `Read` type, using the
  # default buffer size.
  fn pub static new(reader: T) -> BufferedReader[T, E] {
    with_capacity(reader, READ_BUFFER_SIZE)
  }

  # Returns a new buffered reader that wraps the given `Read` type, using the
  # specified buffer size.
  #
  # The `reader` argument can be any `Read` type, provided it allows mutation
  # (e.g. a `ref Reader` isn't valid).
  fn pub static with_capacity(reader: T, size: Int) -> BufferedReader[T, E] {
    if size <= 0 { invalid_buffer_size(size) }

    BufferedReader(
      inner: reader,
      exact: true,
      buffer: ByteArray.new,
      capacity: size,
      offset: 0,
    )
  }
}

impl BufferedRead[E] for BufferedReader {
  fn mut fill_buffer -> Result[Int, E] {
    if @offset < @buffer.size { return Result.Ok(@buffer.size - @offset) }

    @buffer.clear
    @offset = 0

    if @exact {
      match @inner.read_exact(into: @buffer, size: @capacity) {
        case Ok(_) or Error(EndOfInput) -> {}
        case Error(Read(e)) -> throw e
      }
    } else {
      try @inner.read(into: @buffer, size: @capacity)
    }

    Result.Ok(@buffer.size)
  }

  fn mut read_buffer(into: mut ByteArray, size: Int) -> Int {
    let end = min(@offset + size, @buffer.size)
    let len = end - @offset

    into.append(@buffer.slice(start: @offset, end: end))
    @offset += len
    len
  }

  fn pub mut read_byte -> Result[Option[Int], E] {
    # This somewhat verbose approach ensures that if there are N calls to this
    # method we don't call fill_buffer N times, instead only calling it when we
    # consume all bytes from the buffer.
    match @buffer.get(@offset) {
      case Ok(v) -> {
        @offset += 1
        return Result.Ok(Option.Some(v))
      }
      case _ -> {
        match fill_buffer {
          case Ok(0) -> return Result.Ok(Option.None)
          case Ok(_) -> Result.Ok(@buffer.get(@offset := @offset + 1).ok)
          case Error(e) -> throw e
        }
      }
    }
  }

  fn pub mut peek -> Result[Option[Int], E] {
    match @buffer.get(@offset) {
      case Ok(v) -> Result.Ok(Option.Some(v))
      case _ -> {
        match fill_buffer {
          case Ok(0) -> Result.Ok(Option.None)
          case Ok(_) -> Result.Ok(@buffer.get(@offset).ok)
          case Error(e) -> throw e
        }
      }
    }
  }
}

impl Read[E] for BufferedReader {
  fn pub mut read(into: mut ByteArray, size: Int) -> Result[Int, E] {
    let mut total = 0

    # If the read size is larger than our buffer, there's no point in buffering
    # as we can just read all data at once (of course taking account the bytes
    # still in the buffer).
    if size > @capacity {
      if @offset < @buffer.size { total += read_buffer(into, size) }

      return match size - total {
        case 0 -> Result.Ok(total)
        case n -> Result.Ok(total + try @inner.read(into, size: n))
      }
    }

    while total < size {
      if (try fill_buffer) == 0 { break }

      match read_buffer(into, size - total) {
        case 0 -> break
        case n -> total += n
      }
    }

    Result.Ok(total)
  }
}

# A type that wraps a `Write` type and buffers the output.
#
# Writing to a `Write` type can be expensive. The `BufferedWriter` type
# maintains an in-memory buffer of data to write, flushing it to an underlying
# stream whenever necessary. This can improve performance when performing many
# small writes using the same stream. If writes instead involve large data sizes
# or the writes are rare, the use of this type isn't likely to bring any
# benefits.
#
# It's recommended to call `BufferedWriter.flush` before dropping a
# `BufferedWriter`. While this type implements `std.drop.Drop` and tries to
# flush the buffer when it's dropped, any errors produced by the flush are
# ignored.
#
# # Examples
#
# ```inko
# import std.fs.file (WriteOnlyFile)
# import std.io (BufferedWriter)
#
# let file = WriteOnlyFile
#   .new('out.txt')
#   .or_panic_with('failed to open the file')
# let writer = BufferedWriter.new(file)
#
# writer.write('hello') # => Result.Ok(nil)
# writer.flush          # => Result.Ok(nil)
# ```
type pub BufferedWriter[T: mut + Write[E], E] {
  # The `Write` type to write data to.
  let pub @inner: T
  let @buffer: ByteArray
  let @size: Int

  # Returns a `BufferedWriter` that writes to `writer`, using the default buffer
  # size of 8 KiB.
  #
  # # Examples
  #
  # ```inko
  # import std.fs.file (WriteOnlyFile)
  # import std.io (BufferedWriter)
  #
  # let file = WriteOnlyFile
  #   .new('out.txt'.to_path)
  #   .or_panic_with('failed to open the file')
  #
  # BufferedWriter.new(file)
  # ```
  fn pub static new(writer: T) -> Self {
    with_capacity(writer, WRITE_BUFFER_SIZE)
  }

  # Returns a `BufferedWriter` that writes to `writer` with a custom buffer
  # size (in bytes).
  #
  # # Panics
  #
  # This method panics if `capacity` is less than or equal to zero.
  #
  # # Examples
  #
  # ```inko
  # import std.fs.file (WriteOnlyFile)
  # import std.io (BufferedWriter)
  #
  # let file = WriteOnlyFile
  #   .new('out.txt'.to_path)
  #   .or_panic_with('failed to open the file')
  #
  # BufferedWriter.with_capacity(file, capacity: 16 * 1024)
  # ```
  fn pub static with_capacity(writer: T, size: Int) -> Self {
    if size <= 0 { invalid_buffer_size(size) }

    Self(inner: writer, buffer: ByteArray.new, size: size)
  }
}

impl Write[E] for BufferedWriter {
  # Writes the entirety of `bytes` to the buffer, flushing it if necessary.
  #
  # # Errors
  #
  # This method returns a `std.io.Error` if the data can't be written to the
  # underlying stream.
  fn pub mut write[B: Bytes](bytes: ref B) -> Result[Nil, E] {
    let len = bytes.size

    # If the data size is the same as the buffer size we might as well just
    # write to the stream directly.
    if len >= @size {
      try flush
      try @inner.write(bytes)
      return Result.Ok(nil)
    }

    if @buffer.size == @size { try flush }

    let rem = @size - @buffer.size

    if len <= rem {
      @buffer.append(bytes)
      return Result.Ok(nil)
    }

    # The buffer isn't full but our data doesn't fit into it. We fill it up and
    # flush it, then write the data to the buffer. This ensures future calls to
    # this method have more buffer space to work with, compared to just a flush
    # plus appending the _entire_ data to the now empty buffer.
    @buffer.append(Slice.new(bytes, start: 0, end: rem))

    let _ = try flush

    @buffer.append(Slice.new(bytes, start: rem, end: len))
    Result.Ok(nil)
  }

  # Writes any data stored in the buffer to the underlying stream, clearing the
  # buffer in the process.
  #
  # Refer to the documentation of `Writer.flush` for more details.
  #
  # # Errors
  #
  # This method returns a `std.io.Error` if the data can't be written to the
  # underlying stream.
  fn pub mut flush -> Result[Nil, E] {
    if @buffer.size > 0 {
      try @inner.write(@buffer)
      @buffer.clear
    }

    Result.Ok(nil)
  }
}

impl Drop for BufferedWriter {
  fn mut drop {
    let _ = flush
  }
}

# An in-memory buffer that supports reads and seeks.
#
# `Buffer` supports any `Bytes` type, such as `String` or `ByteArray`.
#
# The `Buffer` type is useful when a method operates on a `Read` type (e.g. a
# `ReadOnlyFile`), and you want to test that method without performing actual IO
# operations. For example:
#
# ```inko
# import std.io (Buffer, Read)
#
# fn read_string[T: Read + mut](reader: T) -> String {
#   let bytes = ByteArray.new
#
#   reader.read_all(bytes)
#   bytes.into_string
# }
#
# let reader = Buffer.new('hello')
#
# read_string(reader) # => "hello"
# ```
type pub Buffer[T: Bytes] {
  let @bytes: T
  let mut @offset: Int

  # Returns a new `Buffer` wrapping the given `Bytes`.
  fn pub static new(bytes: T) -> Buffer[T] {
    Buffer(bytes: bytes, offset: 0)
  }
}

impl Read[Nil] for Buffer {
  fn pub mut read(into: mut ByteArray, size: Int) -> Result[Int, Nil] {
    Result.Ok(read_buffer(into, size))
  }
}

impl BufferedRead[Nil] for Buffer {
  fn mut fill_buffer -> Result[Int, Nil] {
    Result.Ok(@bytes.size - @offset)
  }

  fn mut read_buffer(into: mut ByteArray, size: Int) -> Int {
    if @offset < @bytes.size {
      let end = min(@offset + size, @bytes.size)
      let len = end - @offset

      into.append(Slice.new(@bytes, start: @offset, end: end))
      @offset += len
      len
    } else {
      0
    }
  }

  fn pub mut read_byte -> Result[Option[Int], Nil] {
    if @offset < @bytes.size {
      Result.Ok(@bytes.get(@offset := @offset + 1).ok)
    } else {
      Result.Ok(Option.None)
    }
  }

  fn pub mut peek -> Result[Option[Int], Nil] {
    if @offset < @bytes.size {
      Result.Ok(@bytes.get(@offset).ok)
    } else {
      Result.Ok(Option.None)
    }
  }
}

impl Seek[Nil] for Buffer {
  fn pub mut seek(position: Int) -> Result[Int, Nil] {
    if position < 0 {
      @offset = @bytes.size + position
    } else {
      @offset = position
    }

    Result.Ok(@offset)
  }
}

impl Format for Buffer if T: Format {
  fn pub fmt(formatter: mut Formatter) {
    formatter
      .object('Buffer')
      .field('bytes', @bytes)
      .field('offset', @offset)
      .finish
  }
}
